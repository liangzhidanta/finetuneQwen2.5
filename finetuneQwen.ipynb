{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2603660c",
   "metadata": {},
   "source": [
    "# 微调Qwen2.5-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af37cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-26 14:00:46,270] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: cannot find -laio: 没有那个文件或目录\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlopen'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlclose'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlerror'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlsym'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `dlvsym'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/home/dzr/anaconda3/envs/mllm/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /data2/dzr/.cache/models/Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 14:00:49,844 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-05-26 14:00:50,260 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /data2/dzr/.cache/models/Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 14:00:52,646 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-05-26 14:00:53,055 - modelscope - INFO - Target directory already exists, skipping creation.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = \"/data2/dzr/.cache\" \n",
    "from collections import OrderedDict, defaultdict\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm  # 引入 tqdm 库\n",
    "import time  # 引入 time 模块\n",
    "import argparse  # 引入 argparse 模块\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from io import BytesIO\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from typing import Dict, List\n",
    "from modelscope import AutoTokenizer, AutoProcessor,Qwen2_5_VLForConditionalGeneration\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "\n",
    "model_ckpt = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(model_ckpt, trust_remote_code=True)\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764cb66",
   "metadata": {},
   "source": [
    "## 定义度量指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ee1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "#---------新增topkloss---------\n",
    "class TopkLoss(nn.Module):\n",
    "    def __init__(self, k=1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output : [B, T, C] 模型输出的logits（未归一化）\n",
    "            target : [B, T, C] one-hot编码 或 [B, T] 类别索引\n",
    "            B = Batch Size        批量大小（数据加载时设置的batch_size）\n",
    "            T = Sequence Length   输出序列的时间步数（output_length=3）\n",
    "            C = Num Classes       类别数量（64个离散目标类别）\n",
    "        \"\"\"\n",
    "        # 转换target为类别索引\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "        \n",
    "        B, T, C = output.shape\n",
    "        output_flat = output.view(B*T, C)  # [B*T, C]\n",
    "        target_flat = target.contiguous().view(-1)  # [B*T]\n",
    "        \n",
    "        # 计算Top-k正确性\n",
    "        _, topk_indices = torch.topk(output_flat, self.k, dim=1)  # [B*T, k]\n",
    "        correct = topk_indices.eq(target_flat.unsqueeze(1)).any(dim=1)  # [B*T]\n",
    "        \n",
    "        # 计算损失（仅惩罚Top-k错误的样本）\n",
    "        loss = F.cross_entropy(output_flat, target_flat, reduction='none')  # [B*T]，表示每个样本的预测是否在 Top-K 中命中真实标签\n",
    "        masked_loss = loss * ~correct  # 仅保留错误样本的损失值，正确样本的损失被置零\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return masked_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return masked_loss.sum()\n",
    "        return masked_loss\n",
    "\n",
    "#------------新增HybridLoss--------------\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, k=3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # 混合权重\n",
    "        self.k = k\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        \"\"\"\n",
    "        output : [B, T, C]\n",
    "        target : [B, T]\n",
    "        \"\"\"\n",
    "        # 转换target为类别索引\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "        \n",
    "        B, T, C = output.shape\n",
    "        \n",
    "        # 常规交叉熵损失（保持生成特性）\n",
    "        ce_loss = self.ce(output.view(-1, C), target.view(-1))  # [B*T]\n",
    "        \n",
    "        # Top-K增强损失\n",
    "        _, topk = output.topk(self.k, dim=-1)  # [B, T, k]\n",
    "        correct = topk.eq(target.unsqueeze(-1)).any(-1)  # [B, T]\n",
    "        topk_loss = (1 - correct.float()).mean()  # 错误率\n",
    "        \n",
    "        # 时间依赖惩罚项\n",
    "        seq_penalty = self._sequence_consistency(output, target)  # [1]\n",
    "        \n",
    "        return self.alpha*ce_loss.mean() + (1-self.alpha)*topk_loss + seq_penalty\n",
    "        \n",
    "    def _sequence_consistency(self, output, target):\n",
    "        \"\"\"\n",
    "        惩罚相邻时间步预测不一致的情况\n",
    "        \"\"\"\n",
    "        preds = output.argmax(-1)  # [B, T]\n",
    "        diff = (preds[:, 1:] != preds[:, :-1]).float().mean()\n",
    "        return diff * 0.2  # 可调节系数\n",
    "    \n",
    "#-------------新增CrossEntropyloss-----------------\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')  # 始终返回非归约结果\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # 处理one-hot编码目标\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "\n",
    "        # 重塑维度\n",
    "        output = output.view(-1, output.size(-1))  # [B*T, C]\n",
    "        target = target.view(-1)                   # [B*T]\n",
    "\n",
    "        # 计算基础损失\n",
    "        ce_loss = self.ce(output, target)\n",
    "        \n",
    "        # 自定义归约方式\n",
    "        if self.reduction == 'mean':\n",
    "            return ce_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return ce_loss.sum()\n",
    "        return ce_loss  # 'none'模式返回原始形状\n",
    "\n",
    "def calculate_accuracy(output, target, k=3):\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "        with torch.no_grad():\n",
    "            _, pred = output.topk(k, dim=-1)  # [B, T, k]\n",
    "            correct = pred.eq(target.unsqueeze(-1)).any(dim=-1)\n",
    "            return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7152d0",
   "metadata": {},
   "source": [
    "## Processer\n",
    "### 构建多模态提示词并提取视觉输入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb251bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_and_inputs(sample: Dict, hist_steps: int = 5) -> Dict:\n",
    "    \"\"\"构建多模态提示词并提取视觉输入\n",
    "    Args:\n",
    "        sample: 包含多模态数据的样本\n",
    "        hist_steps: 使用历史时间步数（默认为5）\n",
    "    Returns:\n",
    "        包含处理后的提示词和视觉输入的字典\n",
    "    \"\"\"\n",
    "    # 提取并规范化路径\n",
    "    def normalize_paths(path_list: List[str]) -> List[str]:\n",
    "        return [os.path.normpath(p) for p in path_list]\n",
    "    # 处理所有路径\n",
    "    video_paths = normalize_paths(sample['video_paths'][:hist_steps])\n",
    "    heatmap_paths = normalize_paths(sample['heatmap_paths'][:hist_steps])\n",
    "    gps_data = sample['gps'][:hist_steps].tolist()\n",
    "    \n",
    "    # 构建时间序列提示词\n",
    "    prompt_parts = []\n",
    "    for step in range(hist_steps):\n",
    "        time_label = f\"t-{hist_steps-1-step}\" if step < hist_steps-1 else \"Current time (t)\"\n",
    "        \n",
    "        # GPS数据格式化（假设张量存储的是经度、纬度）\n",
    "        lon, lat = gps_data[step]\n",
    "        gps_str = f\"longitude:{lon:.6f}, dimension:{lat:.6f}\"\n",
    "        \n",
    "        # 添加多模态信息块\n",
    "        prompt_part = (\n",
    "            f\"-time:{time_label}\"\n",
    "            f\"-gps:{gps_str}\"\n",
    "        )\n",
    "        prompt_parts.append(prompt_part)\n",
    "    \n",
    "    # 组合完整提示词\n",
    "    system_prompt = \"Please analyze spatiotemporal multimodal data and predict the beam indices for the next three time steps (t+1, t+2, t+3).\"\n",
    "    full_prompt = (\n",
    "        f\"{system_prompt}\" \n",
    "        + \"\".join(prompt_parts) \n",
    "    )\n",
    "    \n",
    "    # 提取所有视觉路径（RGB + 热力图）\n",
    "    all_image_paths = [p for pair in zip(video_paths, heatmap_paths) for p in pair]\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": full_prompt,\n",
    "        \"image_paths\": all_image_paths,\n",
    "        \"labels\": sample['target_mmwave'].argmax(dim=-1).tolist()  # 假设索引是最大值位置\n",
    "    }\n",
    "\n",
    "# 示例使用 ---------------------------------------------------\n",
    "def process_sample(sample, processor):  # 添加processor参数\n",
    "    # Step 1: 构建提示词和获取图像路径\n",
    "    processed = build_prompt_and_inputs(sample)\n",
    "    \n",
    "    # Step 2: 构建messages结构\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"image\", \"image\": path} for path in processed[\"image_paths\"]] + \n",
    "                  [{\"type\": \"text\", \"text\": processed[\"prompt\"]}]\n",
    "    }]\n",
    "    \n",
    "    # Step 3: 使用传入的processor处理输入\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    return inputs, processed[\"labels\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39048644",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c95078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n",
    "\n",
    "class QwenVisionDataset(Dataset):\n",
    "    def __init__(self, data_csv_paths, modal='mmwave_gps', input_length=8, output_length=3):\n",
    "        self.data_csv_paths = data_csv_paths\n",
    "        self.modal = modal\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        \n",
    "        # 特征列映射\n",
    "        self.features_column = {\n",
    "            # 'rgbs': 'unit1_rgb',\n",
    "            'rgbs': 'unit1_camera_resized',\n",
    "            'u1_loc': 'unit1_loc',\n",
    "            'u2_loc': 'unit2_loc',\n",
    "            'mmwave': 'unit1_pwr_60ghz',\n",
    "            'heatmap': 'unit1_mmwave_heatmap'  # 新增热力图列\n",
    "        }\n",
    "        \n",
    "        # 初始化滑动窗口\n",
    "        self.window_samples = []\n",
    "        for seq_idx, data_csv_path in enumerate(self.data_csv_paths):\n",
    "            data_csv = pd.read_csv(data_csv_path)\n",
    "            for seq_id in data_csv['seq_index'].unique():\n",
    "                seq_data = data_csv[data_csv['seq_index'] == seq_id]\n",
    "                if len(seq_data) >= self.input_length:\n",
    "                    for start_idx in range(len(seq_data) - self.input_length + 1):\n",
    "                        self.window_samples.append((seq_idx, seq_id, start_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx, seq_id, start_idx = self.window_samples[idx]\n",
    "        base_path = os.path.dirname(self.data_csv_paths[seq_idx])\n",
    "        data_csv = pd.read_csv(self.data_csv_paths[seq_idx])\n",
    "        seq_data = data_csv[data_csv['seq_index'] == seq_id]\n",
    "        \n",
    "        # 获取原始路径数据\n",
    "        window_data = {\n",
    "            'video_paths': \n",
    "            seq_data[self.features_column['rgbs']]\n",
    "            .iloc[start_idx:start_idx+self.input_length] \n",
    "            .tolist(),\n",
    "            'heatmap_paths': \n",
    "            seq_data[self.features_column['heatmap']]\n",
    "            .iloc[start_idx:start_idx+self.input_length] \n",
    "            .tolist()\n",
    "        }\n",
    "\n",
    "        # 处理GPS数据\n",
    "        gps = []\n",
    "        for i in range(self.input_length):\n",
    "            u1_loc = os.path.join(base_path, seq_data[self.features_column['u1_loc']].iloc[start_idx+i])\n",
    "            u2_loc = os.path.join(base_path, seq_data[self.features_column['u2_loc']].iloc[start_idx+i])\n",
    "            \n",
    "            with open(u1_loc, 'r') as f:\n",
    "                lat1, lon1 = map(float, f.read().strip().split())\n",
    "            with open(u2_loc, 'r') as f:\n",
    "                lat2, lon2 = map(float, f.read().strip().split())\n",
    "                \n",
    "            gps.append(torch.tensor([lat2-lat1, lon2-lon1], dtype=torch.float32))\n",
    "        gps = torch.stack(gps)\n",
    "\n",
    "        # 处理mmWave数据\n",
    "        mmwave = []\n",
    "        for i in range(self.input_length):\n",
    "            mmwave_path = os.path.join(base_path, \n",
    "                seq_data[self.features_column['mmwave']].iloc[start_idx+i])\n",
    "            with open(mmwave_path, 'r') as f:\n",
    "                mmwave.append(torch.tensor(\n",
    "                    list(map(float, f.read().strip().split())), \n",
    "                    dtype=torch.float32))\n",
    "        mmwave = torch.stack(mmwave)\n",
    "\n",
    "        # 目标数据（最后output_length个时间步）\n",
    "        target = []\n",
    "        for i in range(self.input_length-self.output_length, self.input_length):\n",
    "            mmwave_path = os.path.join(base_path,\n",
    "                seq_data[self.features_column['mmwave']].iloc[start_idx+i])\n",
    "            with open(mmwave_path, 'r') as f:\n",
    "                target.append(torch.tensor(\n",
    "                    list(map(float, f.read().strip().split())),\n",
    "                    dtype=torch.float32))\n",
    "        target = torch.stack(target)\n",
    "\n",
    "        return {\n",
    "            'video_paths': [os.path.join(base_path, p) for p in window_data['video_paths']],\n",
    "            'heatmap_paths': [os.path.join(base_path, p) for p in window_data['heatmap_paths']],\n",
    "            'gps': gps,\n",
    "            'mmwave': mmwave,\n",
    "            'target_mmwave': target\n",
    "        }\n",
    "\n",
    "def qwen_collate_fn(batch):\n",
    "    collated = {\n",
    "        'video_paths': [item['video_paths'] for item in batch],\n",
    "        'heatmap_paths': [item['heatmap_paths'] for item in batch],\n",
    "        'gps': pad_sequence([item['gps'] for item in batch], batch_first=True),\n",
    "        'mmwave': pad_sequence([item['mmwave'] for item in batch], batch_first=True),\n",
    "        'target_mmwave': pad_sequence([item['target_mmwave'] for item in batch], batch_first=True)\n",
    "    }\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d3200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 CSV files for training.\n"
     ]
    }
   ],
   "source": [
    "dataset_start_idx = 1\n",
    "dataset_end_idx = 9\n",
    "# 定义数据集路径\n",
    "dataset_path = [f'/data2/wzj/Datasets/DeepSense/scenario{i}/' for i in range(dataset_start_idx, dataset_end_idx)]  # scenario1 ~ scenario8\n",
    "\n",
    "data_csv_paths = []\n",
    "for path in dataset_path:\n",
    "    data_csv_paths.extend(glob.glob(os.path.join(path, '*.csv')))\n",
    "\n",
    "print(f\"Found {len(data_csv_paths)} CSV files for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f7b41",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a605cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_paths': ['/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5376_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5377_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5378_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5379_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5380_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5381_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5382_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5383_00_52_36.jpg'],\n",
       " 'heatmap_paths': ['/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1075.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1076.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1077.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1078.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1079.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1080.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1081.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1082.png'],\n",
       " 'gps': tensor([[2.3318e-05, 2.2738e-04],\n",
       "         [2.7988e-05, 2.2698e-04],\n",
       "         [3.2698e-05, 2.2658e-04],\n",
       "         [3.7458e-05, 2.2618e-04],\n",
       "         [4.2258e-05, 2.2588e-04],\n",
       "         [4.7098e-05, 2.2558e-04],\n",
       "         [5.1988e-05, 2.2518e-04],\n",
       "         [5.6918e-05, 2.2488e-04]]),\n",
       " 'mmwave': tensor([[0.0169, 0.0203, 0.0211, 0.0198, 0.0211, 0.0201, 0.0187, 0.0196, 0.0210,\n",
       "          0.0223, 0.0211, 0.0221, 0.0206, 0.0206, 0.0195, 0.0222, 0.0212, 0.0206,\n",
       "          0.0195, 0.0212, 0.0226, 0.0238, 0.0233, 0.0206, 0.0186, 0.0193, 0.0241,\n",
       "          0.0338, 0.0400, 0.0487, 0.0505, 0.0473, 0.0453, 0.0347, 0.0272, 0.0239,\n",
       "          0.0217, 0.0186, 0.0190, 0.0197, 0.0215, 0.0233, 0.0239, 0.0260, 0.0256,\n",
       "          0.0212, 0.0199, 0.0196, 0.0191, 0.0191, 0.0199, 0.0193, 0.0192, 0.0186,\n",
       "          0.0192, 0.0192, 0.0183, 0.0183, 0.0184, 0.0190, 0.0184, 0.0182, 0.0171,\n",
       "          0.0159],\n",
       "         [0.0174, 0.0222, 0.0234, 0.0222, 0.0207, 0.0207, 0.0210, 0.0219, 0.0258,\n",
       "          0.0254, 0.0245, 0.0235, 0.0219, 0.0225, 0.0219, 0.0272, 0.0271, 0.0217,\n",
       "          0.0239, 0.0263, 0.0375, 0.0365, 0.0293, 0.0235, 0.0219, 0.0240, 0.0423,\n",
       "          0.0815, 0.1052, 0.1008, 0.1143, 0.1066, 0.0822, 0.0552, 0.0324, 0.0234,\n",
       "          0.0199, 0.0204, 0.0236, 0.0273, 0.0257, 0.0286, 0.0346, 0.0332, 0.0322,\n",
       "          0.0234, 0.0208, 0.0206, 0.0223, 0.0239, 0.0257, 0.0225, 0.0222, 0.0208,\n",
       "          0.0217, 0.0227, 0.0217, 0.0199, 0.0191, 0.0224, 0.0216, 0.0199, 0.0185,\n",
       "          0.0163],\n",
       "         [0.0186, 0.0225, 0.0244, 0.0212, 0.0214, 0.0213, 0.0245, 0.0251, 0.0272,\n",
       "          0.0253, 0.0239, 0.0214, 0.0184, 0.0213, 0.0226, 0.0284, 0.0267, 0.0227,\n",
       "          0.0232, 0.0318, 0.0365, 0.0320, 0.0259, 0.0198, 0.0204, 0.0359, 0.0623,\n",
       "          0.1012, 0.1065, 0.0929, 0.0903, 0.0835, 0.0531, 0.0334, 0.0219, 0.0197,\n",
       "          0.0209, 0.0220, 0.0237, 0.0263, 0.0290, 0.0303, 0.0308, 0.0288, 0.0268,\n",
       "          0.0207, 0.0185, 0.0188, 0.0205, 0.0240, 0.0241, 0.0213, 0.0209, 0.0204,\n",
       "          0.0192, 0.0207, 0.0202, 0.0202, 0.0206, 0.0221, 0.0209, 0.0190, 0.0187,\n",
       "          0.0172],\n",
       "         [0.0184, 0.0218, 0.0214, 0.0197, 0.0225, 0.0263, 0.0285, 0.0309, 0.0290,\n",
       "          0.0241, 0.0215, 0.0195, 0.0185, 0.0244, 0.0266, 0.0298, 0.0326, 0.0228,\n",
       "          0.0275, 0.0320, 0.0305, 0.0257, 0.0222, 0.0200, 0.0270, 0.0518, 0.0799,\n",
       "          0.1019, 0.0933, 0.0828, 0.0704, 0.0567, 0.0351, 0.0226, 0.0194, 0.0188,\n",
       "          0.0228, 0.0268, 0.0269, 0.0296, 0.0321, 0.0330, 0.0290, 0.0249, 0.0204,\n",
       "          0.0191, 0.0193, 0.0190, 0.0207, 0.0223, 0.0220, 0.0203, 0.0211, 0.0201,\n",
       "          0.0192, 0.0189, 0.0181, 0.0193, 0.0196, 0.0205, 0.0204, 0.0193, 0.0178,\n",
       "          0.0169],\n",
       "         [0.0199, 0.0212, 0.0240, 0.0281, 0.0319, 0.0373, 0.0405, 0.0387, 0.0312,\n",
       "          0.0220, 0.0185, 0.0214, 0.0259, 0.0320, 0.0423, 0.0427, 0.0340, 0.0379,\n",
       "          0.0461, 0.0604, 0.0454, 0.0259, 0.0245, 0.0357, 0.0627, 0.1006, 0.1222,\n",
       "          0.1290, 0.1155, 0.0817, 0.0676, 0.0495, 0.0306, 0.0206, 0.0206, 0.0200,\n",
       "          0.0239, 0.0297, 0.0308, 0.0351, 0.0396, 0.0350, 0.0280, 0.0236, 0.0206,\n",
       "          0.0197, 0.0223, 0.0219, 0.0210, 0.0241, 0.0223, 0.0218, 0.0224, 0.0220,\n",
       "          0.0200, 0.0186, 0.0187, 0.0198, 0.0198, 0.0208, 0.0207, 0.0198, 0.0183,\n",
       "          0.0171],\n",
       "         [0.0203, 0.0224, 0.0240, 0.0318, 0.0294, 0.0274, 0.0281, 0.0237, 0.0215,\n",
       "          0.0191, 0.0185, 0.0190, 0.0210, 0.0222, 0.0276, 0.0288, 0.0263, 0.0256,\n",
       "          0.0293, 0.0349, 0.0236, 0.0219, 0.0314, 0.0448, 0.0755, 0.0939, 0.1082,\n",
       "          0.1029, 0.0792, 0.0563, 0.0406, 0.0329, 0.0243, 0.0190, 0.0209, 0.0220,\n",
       "          0.0253, 0.0331, 0.0358, 0.0373, 0.0343, 0.0313, 0.0238, 0.0202, 0.0203,\n",
       "          0.0202, 0.0231, 0.0212, 0.0206, 0.0227, 0.0209, 0.0205, 0.0216, 0.0221,\n",
       "          0.0206, 0.0191, 0.0191, 0.0193, 0.0194, 0.0188, 0.0192, 0.0220, 0.0199,\n",
       "          0.0172],\n",
       "         [0.0214, 0.0263, 0.0292, 0.0378, 0.0287, 0.0271, 0.0238, 0.0210, 0.0196,\n",
       "          0.0192, 0.0205, 0.0200, 0.0232, 0.0256, 0.0295, 0.0349, 0.0354, 0.0302,\n",
       "          0.0321, 0.0257, 0.0225, 0.0270, 0.0390, 0.0473, 0.0642, 0.0705, 0.0747,\n",
       "          0.0773, 0.0669, 0.0450, 0.0292, 0.0242, 0.0235, 0.0217, 0.0219, 0.0223,\n",
       "          0.0302, 0.0410, 0.0395, 0.0360, 0.0320, 0.0267, 0.0228, 0.0229, 0.0246,\n",
       "          0.0234, 0.0234, 0.0247, 0.0253, 0.0240, 0.0201, 0.0203, 0.0215, 0.0244,\n",
       "          0.0257, 0.0229, 0.0207, 0.0203, 0.0202, 0.0198, 0.0202, 0.0272, 0.0261,\n",
       "          0.0179],\n",
       "         [0.0187, 0.0213, 0.0252, 0.0245, 0.0210, 0.0208, 0.0181, 0.0176, 0.0189,\n",
       "          0.0221, 0.0206, 0.0197, 0.0229, 0.0271, 0.0302, 0.0290, 0.0282, 0.0239,\n",
       "          0.0192, 0.0184, 0.0286, 0.0496, 0.0654, 0.0738, 0.0865, 0.0931, 0.0866,\n",
       "          0.0636, 0.0463, 0.0302, 0.0224, 0.0211, 0.0243, 0.0270, 0.0373, 0.0356,\n",
       "          0.0529, 0.0608, 0.0455, 0.0315, 0.0258, 0.0227, 0.0208, 0.0240, 0.0285,\n",
       "          0.0224, 0.0211, 0.0230, 0.0223, 0.0202, 0.0187, 0.0184, 0.0189, 0.0205,\n",
       "          0.0219, 0.0215, 0.0191, 0.0192, 0.0198, 0.0219, 0.0216, 0.0232, 0.0223,\n",
       "          0.0169]]),\n",
       " 'target_mmwave': tensor([[0.0203, 0.0224, 0.0240, 0.0318, 0.0294, 0.0274, 0.0281, 0.0237, 0.0215,\n",
       "          0.0191, 0.0185, 0.0190, 0.0210, 0.0222, 0.0276, 0.0288, 0.0263, 0.0256,\n",
       "          0.0293, 0.0349, 0.0236, 0.0219, 0.0314, 0.0448, 0.0755, 0.0939, 0.1082,\n",
       "          0.1029, 0.0792, 0.0563, 0.0406, 0.0329, 0.0243, 0.0190, 0.0209, 0.0220,\n",
       "          0.0253, 0.0331, 0.0358, 0.0373, 0.0343, 0.0313, 0.0238, 0.0202, 0.0203,\n",
       "          0.0202, 0.0231, 0.0212, 0.0206, 0.0227, 0.0209, 0.0205, 0.0216, 0.0221,\n",
       "          0.0206, 0.0191, 0.0191, 0.0193, 0.0194, 0.0188, 0.0192, 0.0220, 0.0199,\n",
       "          0.0172],\n",
       "         [0.0214, 0.0263, 0.0292, 0.0378, 0.0287, 0.0271, 0.0238, 0.0210, 0.0196,\n",
       "          0.0192, 0.0205, 0.0200, 0.0232, 0.0256, 0.0295, 0.0349, 0.0354, 0.0302,\n",
       "          0.0321, 0.0257, 0.0225, 0.0270, 0.0390, 0.0473, 0.0642, 0.0705, 0.0747,\n",
       "          0.0773, 0.0669, 0.0450, 0.0292, 0.0242, 0.0235, 0.0217, 0.0219, 0.0223,\n",
       "          0.0302, 0.0410, 0.0395, 0.0360, 0.0320, 0.0267, 0.0228, 0.0229, 0.0246,\n",
       "          0.0234, 0.0234, 0.0247, 0.0253, 0.0240, 0.0201, 0.0203, 0.0215, 0.0244,\n",
       "          0.0257, 0.0229, 0.0207, 0.0203, 0.0202, 0.0198, 0.0202, 0.0272, 0.0261,\n",
       "          0.0179],\n",
       "         [0.0187, 0.0213, 0.0252, 0.0245, 0.0210, 0.0208, 0.0181, 0.0176, 0.0189,\n",
       "          0.0221, 0.0206, 0.0197, 0.0229, 0.0271, 0.0302, 0.0290, 0.0282, 0.0239,\n",
       "          0.0192, 0.0184, 0.0286, 0.0496, 0.0654, 0.0738, 0.0865, 0.0931, 0.0866,\n",
       "          0.0636, 0.0463, 0.0302, 0.0224, 0.0211, 0.0243, 0.0270, 0.0373, 0.0356,\n",
       "          0.0529, 0.0608, 0.0455, 0.0315, 0.0258, 0.0227, 0.0208, 0.0240, 0.0285,\n",
       "          0.0224, 0.0211, 0.0230, 0.0223, 0.0202, 0.0187, 0.0184, 0.0189, 0.0205,\n",
       "          0.0219, 0.0215, 0.0191, 0.0192, 0.0198, 0.0219, 0.0216, 0.0232, 0.0223,\n",
       "          0.0169]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = QwenVisionDataset(\n",
    "    data_csv_paths,\n",
    "    input_length=8,\n",
    "    output_length=3\n",
    ")\n",
    "dataset[998]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4e860",
   "metadata": {},
   "source": [
    "### 划分数据集（抽出1600个样本微调）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febef180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "# 固定随机种子确保每次结果一致（可选）\n",
    "random.seed(42)\n",
    "\n",
    "# 原始数据集有约 14400 个样本\n",
    "total_samples = len(dataset)\n",
    "\n",
    "# 随机选出 1600 个样本的索引\n",
    "subset_indices = random.sample(range(total_samples), 1600)\n",
    "\n",
    "# 创建新的 dataset\n",
    "small_dataset = Subset(dataset, subset_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6813b67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training samples: 1280\n",
      "Total Validation samples: 160\n",
      "Total Testing samples: 160\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(small_dataset))\n",
    "val_size = int(0.1 * len(small_dataset))\n",
    "test_size = len(small_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Total Training samples: {len(train_dataset)}\")\n",
    "print(f\"Total Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Total Testing samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8309968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def custom_collate(batch):\n",
    "    # 直接返回样本列表，不进行合并\n",
    "    return batch\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,  \n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  \n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  \n",
    "    collate_fn=custom_collate,\n",
    "    pin_memory=True if torch.cuda.is_available() else False,\n",
    ")\n",
    "\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712a0a4",
   "metadata": {},
   "source": [
    "## Model\n",
    "### 用Qwen构造带有64类分类头的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2bc543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qwen_and_Head(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()\n",
    "        self.qwen = pretrained_model\n",
    "        joint_hidden_size = 3584\n",
    "\n",
    "        # final head now produces 3×64 dims\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(joint_hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 3 * 64),    # 3 timesteps × 64 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values, image_grid_thw):\n",
    "        outputs = self.qwen(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            pixel_values=pixel_values,\n",
    "            image_grid_thw=image_grid_thw,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "        # grab the [CLS] token\n",
    "        last_hidden = outputs.hidden_states[-1]   # (B, L, D)\n",
    "        cls_token   = last_hidden[:, 0, :]        # (B, D)\n",
    "\n",
    "        # project to (B, 3*64) and reshape\n",
    "        logits_flat = self.classifier(cls_token)            # (B, 192)\n",
    "        logits      = logits_flat.view(-1, 3, 64)           # (B, 3, 64)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b7894",
   "metadata": {},
   "source": [
    "### 加载Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4de76fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda (NVIDIA A100-SXM4-80GB)\n"
     ]
    }
   ],
   "source": [
    "# !pip install qwen-vl-utils[decord]==0.0.8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Using device: {device} ({torch.cuda.get_device_name(device)})\")\n",
    "else:\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30343410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 13:48:42,200 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /data2/dzr/.cache/models/Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 13:48:42,485 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3536c3603d84046948ca67987b176b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 15.45 GB\n"
     ]
    }
   ],
   "source": [
    "# 配置 bfloat16 精度\n",
    "finetune_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_ckpt,\n",
    "    torch_dtype=torch.bfloat16,    # 设置模型权重为 bfloat16\n",
    "    device_map=\"cuda\",              # 自动分配设备\n",
    "    trust_remote_code=True,         # 必须开启\n",
    "    return_dict=True\n",
    ").to(device)\n",
    "print(f\"Memory usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22cd9bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2_5_VLForConditionalGeneration(\n",
      "  (model): Qwen2_5_VLModel(\n",
      "    (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
      "      (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
      "        (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
      "      )\n",
      "      (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
      "      (blocks): ModuleList(\n",
      "        (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
      "          (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "          (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "          (attn): Qwen2_5_VLVisionSdpaAttention(\n",
      "            (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
      "            (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (mlp): Qwen2_5_VLMLP(\n",
      "            (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "            (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "            (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (merger): Qwen2_5_VLPatchMerger(\n",
      "        (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (language_model): Qwen2_5_VLTextModel(\n",
      "      (embed_tokens): Embedding(152064, 3584)\n",
      "      (layers): ModuleList(\n",
      "        (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
      "          (self_attn): Qwen2_5_VLSdpaAttention(\n",
      "            (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "            (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "            (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "            (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): Qwen2MLP(\n",
      "            (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "            (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "            (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(finetune_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e842dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load bitsandbytes native library: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda126.so)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 85, in <module>\n",
      "    lib = get_native_library()\n",
      "  File \"/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/bitsandbytes/cextension.py\", line 72, in get_native_library\n",
      "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
      "  File \"/home/dzr/anaconda3/envs/mllm/lib/python3.10/ctypes/__init__.py\", line 452, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/home/dzr/anaconda3/envs/mllm/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda126.so)\n",
      "\n",
      "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
      "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
      "and open an issue at: https://github.com/bitsandbytes-foundation/bitsandbytes/issues\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#  冻结原模型所有参数\n",
    "for param in finetune_model.parameters():\n",
    "    param.requires_grad = False\n",
    "#  配置 LoRA Adapter\n",
    "lora_config = LoraConfig(\n",
    "    r=8,                         # LoRA rank\n",
    "    lora_alpha=32,               # LoRA scaling\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "#  注入 LoRA\n",
    "qwen_lora = get_peft_model(finetune_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12e69a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 15.46 GB\n",
      "Qwen_and_Head(\n",
      "  (qwen): PeftModelForCausalLM(\n",
      "    (base_model): LoraModel(\n",
      "      (model): Qwen2_5_VLForConditionalGeneration(\n",
      "        (model): Qwen2_5_VLModel(\n",
      "          (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
      "            (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
      "              (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
      "            )\n",
      "            (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
      "            (blocks): ModuleList(\n",
      "              (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
      "                (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "                (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "                (attn): Qwen2_5_VLVisionSdpaAttention(\n",
      "                  (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
      "                  (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "                )\n",
      "                (mlp): Qwen2_5_VLMLP(\n",
      "                  (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "                  (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "                  (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
      "                  (act_fn): SiLU()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (merger): Qwen2_5_VLPatchMerger(\n",
      "              (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "              (mlp): Sequential(\n",
      "                (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "                (1): GELU(approximate='none')\n",
      "                (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (language_model): Qwen2_5_VLTextModel(\n",
      "            (embed_tokens): Embedding(152064, 3584)\n",
      "            (layers): ModuleList(\n",
      "              (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
      "                (self_attn): Qwen2_5_VLSdpaAttention(\n",
      "                  (q_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=3584, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "                  (v_proj): lora.Linear(\n",
      "                    (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.1, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=3584, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=512, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                    (lora_magnitude_vector): ModuleDict()\n",
      "                  )\n",
      "                  (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "                  (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "                )\n",
      "                (mlp): Qwen2MLP(\n",
      "                  (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                  (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "                  (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "                  (act_fn): SiLU()\n",
      "                )\n",
      "                (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "                (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "              )\n",
      "            )\n",
      "            (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "            (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "          )\n",
      "        )\n",
      "        (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=3584, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=192, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "finetuner = Qwen_and_Head(pretrained_model=qwen_lora).to(device)\n",
    "print(f\"Memory usage: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "print(finetuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f8aeb",
   "metadata": {},
   "source": [
    "### 检查输入样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fc16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Please analyze spatiotemporal multimodal data and predict the beam indices for the next three time steps (t+1, t+2, t+3).-time:t-4-gps:longitude:0.000087, dimension:0.000158-time:t-3-gps:longitude:0.000084, dimension:0.000159-time:t-2-gps:longitude:0.000081, dimension:0.000159-time:t-1-gps:longitude:0.000078, dimension:0.000159-time:Current time (t)-gps:longitude:0.000075, dimension:0.000159', 'image_paths': ['/data2/wzj/Datasets/DeepSense/scenario2/unit1/camera_resized/image_BS1_976_02_12_21.jpg', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/mmWave_heatmap/mmWave_power_123.png', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/camera_resized/image_BS1_977_02_12_21.jpg', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/mmWave_heatmap/mmWave_power_124.png', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/camera_resized/image_BS1_978_02_12_21.jpg', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/mmWave_heatmap/mmWave_power_125.png', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/camera_resized/image_BS1_979_02_12_21.jpg', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/mmWave_heatmap/mmWave_power_126.png', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/camera_resized/image_BS1_980_02_12_22.jpg', '/data2/wzj/Datasets/DeepSense/scenario2/unit1/mmWave_heatmap/mmWave_power_127.png'], 'labels': [11, 12, 13]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': tensor([[151644,   8948,    198,  ..., 151644,  77091,    198]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'pixel_values': tensor([[-1.3105, -1.4127, -1.3689,  ..., -0.5559, -1.0110, -1.1105],\n",
      "        [-1.2229, -1.2667, -1.3397,  ..., -1.3096, -1.3238, -1.2527],\n",
      "        [-1.1207, -1.1353, -1.2521,  ..., -0.5417, -0.8688, -1.0678],\n",
      "        ...,\n",
      "        [-0.7996, -0.7996, -0.7996,  ..., -0.2857, -0.2857, -0.2857],\n",
      "        [-0.7996, -0.7996, -0.7996,  ..., -0.2857, -0.2857, -0.2857],\n",
      "        [-0.7996, -0.7996, -0.7996,  ..., -0.2857, -0.2857, -0.2857]],\n",
      "       device='cuda:0'), 'image_grid_thw': tensor([[ 1, 20, 34],\n",
      "        [ 1, 16, 16],\n",
      "        [ 1, 20, 34],\n",
      "        [ 1, 16, 16],\n",
      "        [ 1, 20, 34],\n",
      "        [ 1, 16, 16],\n",
      "        [ 1, 20, 34],\n",
      "        [ 1, 16, 16],\n",
      "        [ 1, 20, 34],\n",
      "        [ 1, 16, 16]], device='cuda:0')}, [11, 12, 13])\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  15833 MiB |  15854 MiB |  31674 MiB |  15841 MiB |\n",
      "|       from large pool |  15821 MiB |  15842 MiB |  31658 MiB |  15837 MiB |\n",
      "|       from small pool |     11 MiB |     11 MiB |     16 MiB |      4 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  15833 MiB |  15854 MiB |  31674 MiB |  15841 MiB |\n",
      "|       from large pool |  15821 MiB |  15842 MiB |  31658 MiB |  15837 MiB |\n",
      "|       from small pool |     11 MiB |     11 MiB |     16 MiB |      4 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  15833 MiB |  15854 MiB |  31674 MiB |  15841 MiB |\n",
      "|       from large pool |  15821 MiB |  15842 MiB |  31658 MiB |  15837 MiB |\n",
      "|       from small pool |     11 MiB |     11 MiB |     16 MiB |      4 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  15872 MiB |  15872 MiB |  15872 MiB |      0 B   |\n",
      "|       from large pool |  15860 MiB |  15860 MiB |  15860 MiB |      0 B   |\n",
      "|       from small pool |     12 MiB |     12 MiB |     12 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  17315 KiB |  14780 MiB |  14810 MiB |  14794 MiB |\n",
      "|       from large pool |  16964 KiB |  14778 MiB |  14794 MiB |  14777 MiB |\n",
      "|       from small pool |    351 KiB |      2 MiB |     16 MiB |     16 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     875    |     886    |    1024    |     149    |\n",
      "|       from large pool |     362    |     363    |     364    |       2    |\n",
      "|       from small pool |     513    |     523    |     660    |     147    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     875    |     886    |    1024    |     149    |\n",
      "|       from large pool |     362    |     363    |     364    |       2    |\n",
      "|       from small pool |     513    |     523    |     660    |     147    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       9    |       9    |       9    |       0    |\n",
      "|       from large pool |       3    |       3    |       3    |       0    |\n",
      "|       from small pool |       6    |       6    |       6    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       8    |      11    |      34    |      26    |\n",
      "|       from large pool |       2    |       3    |       4    |       2    |\n",
      "|       from small pool |       6    |       8    |      30    |      24    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[2324]\n",
    "print(build_prompt_and_inputs(sample))\n",
    "print(process_sample(sample,processor=processor))\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76e7e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本 token 数: 1386\n",
      "图像张数: 10\n",
      "  第 1 张图 → 680 个 patch token\n",
      "  第 2 张图 → 256 个 patch token\n",
      "  第 3 张图 → 680 个 patch token\n",
      "  第 4 张图 → 256 个 patch token\n",
      "  第 5 张图 → 680 个 patch token\n",
      "  第 6 张图 → 256 个 patch token\n",
      "  第 7 张图 → 680 个 patch token\n",
      "  第 8 张图 → 256 个 patch token\n",
      "  第 9 张图 → 680 个 patch token\n",
      "  第 10 张图 → 256 个 patch token\n",
      "图像总 patch token 数: 4680\n"
     ]
    }
   ],
   "source": [
    "# 假设你已经有 process_sample 函数和 processor\n",
    "sample = train_dataset[0]     # 或者任何一个样本\n",
    "\n",
    "# 1) 只做一次前处理（在 CPU 上）\n",
    "inputs, _ = process_sample(sample, processor)\n",
    "\n",
    "# 2) 文本 token 数\n",
    "#    inputs[\"input_ids\"] 的形状是 (1, seq_len)\n",
    "text_token_count = inputs[\"input_ids\"].shape[1]\n",
    "print(f\"文本 token 数: {text_token_count}\")\n",
    "\n",
    "# 3) 图像 token 数\n",
    "#    inputs[\"image_grid_thw\"] 的形状是 (n_images, 3)\n",
    "#      每行 = [T, H, W]，对于静态图片 T=1，token = H*W\n",
    "grid = inputs[\"image_grid_thw\"].cpu().long()  # (n_images, 3)\n",
    "T, H, W = grid.unbind(dim=1)                 # 拆成三个向量\n",
    "tokens_per_image = (H * W).tolist()           # list 长度 = n_images\n",
    "total_image_tokens = sum(tokens_per_image)\n",
    "\n",
    "print(f\"图像张数: {grid.shape[0]}\")\n",
    "for i, nt in enumerate(tokens_per_image):\n",
    "    print(f\"  第 {i+1} 张图 → {nt} 个 patch token\")\n",
    "print(f\"图像总 patch token 数: {total_image_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9df97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_epoch(model, processor, train_loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        # 1) run process_sample on every raw sample\n",
    "        batch_inputs = {\"input_ids\": [], \"attention_mask\": [], \"pixel_values\": [],\"image_grid_thw\": []}\n",
    "        batch_labels = []\n",
    "\n",
    "        for sample in batch:\n",
    "            inputs, label = process_sample(sample, processor)\n",
    "            batch_inputs[\"input_ids\"].append(inputs[\"input_ids\"])\n",
    "            batch_inputs[\"attention_mask\"].append(inputs[\"attention_mask\"])\n",
    "            batch_inputs[\"pixel_values\"].append(inputs[\"pixel_values\"])\n",
    "            batch_inputs[\"image_grid_thw\"].append(inputs[\"image_grid_thw\"])\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        # 2) stack/cat into real batched tensors\n",
    "        batch_inputs = {\n",
    "            k: torch.cat(v, dim=0).to(device)\n",
    "            for k, v in batch_inputs.items()\n",
    "        }\n",
    "        batch_labels = torch.tensor(batch_labels, dtype=torch.long, device=device)\n",
    "        # print(batch_inputs)\n",
    "        # 3) forward + loss + backward\n",
    "        optimizer.zero_grad()\n",
    "        #  forward in mixed precision\n",
    "        with autocast():\n",
    "            logits = model(**batch_inputs)\n",
    "            loss   = criterion(logits, batch_labels)\n",
    "\n",
    "        #  scale, backward, unscale, step, update\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, processor, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct_1 = 0\n",
    "    total_correct_3 = 0\n",
    "    total_correct_5 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"evaluating\"):\n",
    "            # 1) process each sample\n",
    "            batch_inputs = {\"input_ids\": [], \"attention_mask\": [], \"pixel_values\": [], \"image_grid_thw\": []}\n",
    "            batch_labels = []\n",
    "\n",
    "            for sample in batch:\n",
    "                inputs, label = process_sample(sample, processor)\n",
    "                batch_inputs[\"input_ids\"].append(inputs[\"input_ids\"])\n",
    "                batch_inputs[\"attention_mask\"].append(inputs[\"attention_mask\"])\n",
    "                batch_inputs[\"pixel_values\"].append(inputs[\"pixel_values\"])\n",
    "                batch_inputs[\"image_grid_thw\"].append(inputs[\"image_grid_thw\"])\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            # 2) stack into batched tensors\n",
    "            batch_inputs = {k: torch.cat(v, dim=0).to(device) for k, v in batch_inputs.items()}\n",
    "            batch_labels = torch.tensor(batch_labels, dtype=torch.long, device=device)\n",
    "\n",
    "            # 3) forward + loss\n",
    "            with autocast():\n",
    "                logits = model(**batch_inputs)\n",
    "                loss = criterion(logits, batch_labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # 4) calculate top-k correct counts\n",
    "            total_correct_1 += calculate_accuracy(logits, batch_labels, k=1)\n",
    "            total_correct_3 += calculate_accuracy(logits, batch_labels, k=3)\n",
    "            total_correct_5 += calculate_accuracy(logits, batch_labels, k=5)\n",
    "\n",
    "    # compute averages\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    avg_acc1 = total_correct_1 / len(val_loader)\n",
    "    avg_acc3 = total_correct_3 / len(val_loader)\n",
    "    avg_acc5 = total_correct_5 / len(val_loader)\n",
    "\n",
    "    return avg_loss, avg_acc1, avg_acc3, avg_acc5\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e7f54",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaeb6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 1e-5\n",
    "patience  = 5\n",
    "checkpoint_dir = \"/data2/dzr/finetune/finetunning_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a8d85a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1218613/301521330.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "model = finetuner.to(device)\n",
    "model.qwen.gradient_checkpointing_enable()\n",
    "scaler    = GradScaler()\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5, \n",
    "        patience=5,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9cb3c",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "217077e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test = train_epoch(model,processor,train_loader,criterion,optimizer,scaler,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f0ee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/80 [00:00<?, ?it/s]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "Training:   1%|▏         | 1/80 [00:30<40:10, 30.51s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:   2%|▎         | 2/80 [00:59<38:27, 29.58s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:   4%|▍         | 3/80 [01:35<41:36, 32.42s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:   5%|▌         | 4/80 [02:27<51:03, 40.31s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:   6%|▋         | 5/80 [03:28<59:45, 47.80s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:   8%|▊         | 6/80 [04:29<1:04:23, 52.21s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:   9%|▉         | 7/80 [05:30<1:07:01, 55.09s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:  10%|█         | 8/80 [06:31<1:08:19, 56.94s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:  11%|█▏        | 9/80 [07:32<1:08:59, 58.31s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:  12%|█▎        | 10/80 [08:33<1:08:50, 59.01s/it]/tmp/ipykernel_1218613/1132776098.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dzr/anaconda3/envs/mllm/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Training:  14%|█▍        | 11/80 [09:35<1:00:08, 52.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 验证\u001b[39;00m\n\u001b[1;32m     22\u001b[0m val_loss ,acc_1 ,acc_3 ,acc_5 \u001b[38;5;241m=\u001b[39m evaluate(model,processor,val_loader,criterion,device)\n",
      "Cell \u001b[0;32mIn[18], line 13\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, processor, train_loader, criterion, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m---> 13\u001b[0m     inputs, label \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     batch_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     15\u001b[0m     batch_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m, in \u001b[0;36mprocess_sample\u001b[0;34m(sample, processor)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Step 3: 使用传入的processor处理输入\u001b[39;00m\n\u001b[1;32m     62\u001b[0m text \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     63\u001b[0m     messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m image_inputs, video_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_vision_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(\n\u001b[1;32m     68\u001b[0m     text\u001b[38;5;241m=\u001b[39m[text],\n\u001b[1;32m     69\u001b[0m     images\u001b[38;5;241m=\u001b[39mimage_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/mllm/lib/python3.10/site-packages/qwen_vl_utils/vision_process.py:330\u001b[0m, in \u001b[0;36mprocess_vision_info\u001b[0;34m(conversations)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vision_info \u001b[38;5;129;01min\u001b[39;00m vision_infos:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vision_info \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_url\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vision_info:\n\u001b[0;32m--> 330\u001b[0m         image_inputs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfetch_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvision_info\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vision_info:\n\u001b[1;32m    332\u001b[0m         video_inputs\u001b[38;5;241m.\u001b[39mappend(fetch_video(vision_info))\n",
      "File \u001b[0;32m~/anaconda3/envs/mllm/lib/python3.10/site-packages/qwen_vl_utils/vision_process.py:122\u001b[0m, in \u001b[0;36mfetch_image\u001b[0;34m(ele, size_factor)\u001b[0m\n\u001b[1;32m    114\u001b[0m     max_pixels \u001b[38;5;241m=\u001b[39m ele\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_pixels\u001b[39m\u001b[38;5;124m\"\u001b[39m, MAX_PIXELS)\n\u001b[1;32m    115\u001b[0m     resized_height, resized_width \u001b[38;5;241m=\u001b[39m smart_resize(\n\u001b[1;32m    116\u001b[0m         height,\n\u001b[1;32m    117\u001b[0m         width,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m         max_pixels\u001b[38;5;241m=\u001b[39mmax_pixels,\n\u001b[1;32m    121\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresized_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresized_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m~/anaconda3/envs/mllm/lib/python3.10/site-packages/PIL/Image.py:2356\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2348\u001b[0m         )\n\u001b[1;32m   2349\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2350\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2351\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2352\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2353\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2354\u001b[0m         )\n\u001b[0;32m-> 2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def format_time(seconds):\n",
    "    mins, sec = divmod(seconds, 60)\n",
    "    hrs, mins = divmod(mins, 60)\n",
    "    return f\"{int(hrs)}h {int(mins)}m {int(sec)}s\"\n",
    "\n",
    "num_epochs = epochs\n",
    "best_val_loss = float('inf') # 初始化为“正无限大”（infinity）\n",
    "\n",
    "# 确保保存模型的目录存在\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 记录训练开始时间\n",
    "training_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # 训练\n",
    "    train_loss = train_epoch(model,processor,train_loader,criterion,optimizer,scaler,device)\n",
    "\n",
    "    # 验证\n",
    "    val_loss ,acc_1 ,acc_3 ,acc_5 = evaluate(model,processor,val_loader,criterion,device)\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # 计算剩余时间\n",
    "    elapsed_time = epoch_end_time - training_start_time\n",
    "    avg_epoch_time = elapsed_time / (epoch + 1)\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    remaining_time = avg_epoch_time * remaining_epochs\n",
    "\n",
    "    # 转换为更易读的格式\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f},Val Accuracy@3: {acc_3.item():.4f}\")\n",
    "    print(f\"Val Accuracy@1: {acc_1.item():.4f}, Val Accuracy@5: {acc_5.item():.4f}\")\n",
    "    print(f\"Epoch Duration: {format_time(epoch_duration)}, Estimated Remaining Time: {format_time(remaining_time)}\")\n",
    "\n",
    "    # 更新学习率调度器\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_path = os.path.join(checkpoint_dir, 'multimodal_encoder_decoder_best.pth')\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model at epoch {epoch+1} to {best_model_path}\")\n",
    "        early_stop_counter = 0  # 重置计数器\n",
    "    else:\n",
    "        early_stop_counter += 1  # 增加计数器\n",
    "\n",
    "    # 如果验证损失连续多个 epoch 没有改善，则停止训练\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break  # 提前停止训练\n",
    "\n",
    "    # 每隔若干个 epoch 保存模型\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'multimodal_encoder_decoder_epoch_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved model at epoch {epoch+1} to {checkpoint_path}\")\n",
    "\n",
    "# 7. 测试评估\n",
    "\n",
    "# 加载最佳模型\n",
    "best_model_path = os.path.join(checkpoint_dir, 'multimodal_encoder_decoder_best.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(\"Loaded best model for testing.\")\n",
    "else:\n",
    "    print(f\"Best model not found at {best_model_path}. Skipping test evaluation.\")\n",
    "\n",
    "# 定义测试评估函数（可以与验证相同）\n",
    "\n",
    "\n",
    "test_loss ,test_acc1 ,test_acc3 ,test_acc5 = evaluate(model,processor,test_loader,criterion,device)\n",
    "print(f\"Test Loss : {test_loss:.4f};Test Accuracy@3 : {test_acc3:.4f}\")\n",
    "print(f\"Test Accuracy@1 : {test_acc1:.4f};Test Accuracy@5 : {test_acc5:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
