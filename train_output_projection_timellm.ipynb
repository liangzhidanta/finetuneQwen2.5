{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2603660c",
   "metadata": {},
   "source": [
    "# 微调Qwen2.5-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af37cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:48:49,092 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /data2/dzr/.cache/models/Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:48:49,334 - modelscope - INFO - Target directory already exists, skipping creation.\n",
      "2025-06-01 16:48:50,566 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /data2/dzr/.cache/models/Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:48:50,826 - modelscope - INFO - Target directory already exists, skipping creation.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = \"/data2/dzr/.cache\" \n",
    "from collections import OrderedDict, defaultdict\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm  # 引入 tqdm 库\n",
    "import time  # 引入 time 模块\n",
    "import argparse  # 引入 argparse 模块\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from io import BytesIO\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from typing import Dict, List\n",
    "from modelscope import AutoTokenizer, AutoProcessor,Qwen2_5_VLForConditionalGeneration\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "model_ckpt = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, trust_remote_code=True)\n",
    "processor = AutoProcessor.from_pretrained(model_ckpt, trust_remote_code=True)\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c8eadf",
   "metadata": {},
   "source": [
    "## 指定设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af77c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install qwen-vl-utils[decord]==0.0.8\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764cb66",
   "metadata": {},
   "source": [
    "## 定义度量指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ee1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "#---------新增topkloss---------\n",
    "class TopkLoss(nn.Module):\n",
    "    def __init__(self, k=1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output : [B, T, C] 模型输出的logits（未归一化）\n",
    "            target : [B, T, C] one-hot编码 或 [B, T] 类别索引\n",
    "            B = Batch Size        批量大小（数据加载时设置的batch_size）\n",
    "            T = Sequence Length   输出序列的时间步数（output_length=3）\n",
    "            C = Num Classes       类别数量（64个离散目标类别）\n",
    "        \"\"\"\n",
    "        # 转换target为类别索引\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "        \n",
    "        B, T, C = output.shape\n",
    "        output_flat = output.view(B*T, C)  # [B*T, C]\n",
    "        target_flat = target.contiguous().view(-1)  # [B*T]\n",
    "        \n",
    "        # 计算Top-k正确性\n",
    "        _, topk_indices = torch.topk(output_flat, self.k, dim=1)  # [B*T, k]\n",
    "        correct = topk_indices.eq(target_flat.unsqueeze(1)).any(dim=1)  # [B*T]\n",
    "        \n",
    "        # 计算损失（仅惩罚Top-k错误的样本）\n",
    "        loss = F.cross_entropy(output_flat, target_flat, reduction='none')  # [B*T]，表示每个样本的预测是否在 Top-K 中命中真实标签\n",
    "        masked_loss = loss * ~correct  # 仅保留错误样本的损失值，正确样本的损失被置零\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return masked_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return masked_loss.sum()\n",
    "        return masked_loss\n",
    "\n",
    "#------------新增HybridLoss--------------\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.7, k=3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # 混合权重\n",
    "        self.k = k\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        \"\"\"\n",
    "        output : [B, T, C]\n",
    "        target : [B, T]\n",
    "        \"\"\"\n",
    "        # 转换target为类别索引\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "        \n",
    "        B, T, C = output.shape\n",
    "        \n",
    "        # 常规交叉熵损失（保持生成特性）\n",
    "        ce_loss = self.ce(output.view(-1, C), target.view(-1))  # [B*T]\n",
    "        \n",
    "        # Top-K增强损失\n",
    "        _, topk = output.topk(self.k, dim=-1)  # [B, T, k]\n",
    "        correct = topk.eq(target.unsqueeze(-1)).any(-1)  # [B, T]\n",
    "        topk_loss = (1 - correct.float()).mean()  # 错误率\n",
    "        \n",
    "        # 时间依赖惩罚项\n",
    "        seq_penalty = self._sequence_consistency(output, target)  # [1]\n",
    "        \n",
    "        return self.alpha*ce_loss.mean() + (1-self.alpha)*topk_loss + seq_penalty\n",
    "        \n",
    "    def _sequence_consistency(self, output, target):\n",
    "        \"\"\"\n",
    "        惩罚相邻时间步预测不一致的情况\n",
    "        \"\"\"\n",
    "        preds = output.argmax(-1)  # [B, T]\n",
    "        diff = (preds[:, 1:] != preds[:, :-1]).float().mean()\n",
    "        return diff * 0.2  # 可调节系数\n",
    "    \n",
    "#-------------新增CrossEntropyloss-----------------\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')  # 始终返回非归约结果\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # 处理one-hot编码目标\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "\n",
    "        # 重塑维度\n",
    "        output = output.view(-1, output.size(-1))  # [B*T, C]\n",
    "        target = target.view(-1)                   # [B*T]\n",
    "\n",
    "        # 计算基础损失\n",
    "        ce_loss = self.ce(output, target)\n",
    "        \n",
    "        # 自定义归约方式\n",
    "        if self.reduction == 'mean':\n",
    "            return ce_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return ce_loss.sum()\n",
    "        return ce_loss  # 'none'模式返回原始形状\n",
    "\n",
    "def calculate_accuracy(output, target, k=3):\n",
    "        if target.dim() == 3:\n",
    "            target = torch.argmax(target, dim=-1)  # [B, T]\n",
    "        with torch.no_grad():\n",
    "            _, pred = output.topk(k, dim=-1)  # [B, T, k]\n",
    "            correct = pred.eq(target.unsqueeze(-1)).any(dim=-1)\n",
    "            return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7152d0",
   "metadata": {},
   "source": [
    "## Processer\n",
    "### 构建多模态提示词并提取视觉输入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb251bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_and_inputs(sample: Dict, hist_steps: int = 5) -> Dict:\n",
    "    \"\"\"构建多模态提示词并提取视觉输入\n",
    "    Args:\n",
    "        sample: 包含多模态数据的样本\n",
    "        hist_steps: 使用历史时间步数（默认为5）\n",
    "    Returns:\n",
    "        包含处理后的提示词和视觉输入的字典\n",
    "    \"\"\"\n",
    "    # 提取并规范化路径\n",
    "    def normalize_paths(path_list: List[str]) -> List[str]:\n",
    "        return [os.path.normpath(p) for p in path_list]\n",
    "    # 处理所有路径\n",
    "    video_paths = normalize_paths(sample['video_paths'][:hist_steps])\n",
    "    heatmap_paths = normalize_paths(sample['heatmap_paths'][:hist_steps])\n",
    "    gps_data = sample['gps'][:hist_steps].tolist()\n",
    "    \n",
    "    # 构建时间序列提示词\n",
    "    prompt_parts = []\n",
    "    for step in range(hist_steps):\n",
    "        time_label = f\"t-{hist_steps-1-step}\" if step < hist_steps-1 else \"Current time (t)\"\n",
    "        \n",
    "        # GPS数据格式化（假设张量存储的是经度、纬度）\n",
    "        lon, lat = gps_data[step]\n",
    "        gps_str = f\"longitude:{lon:.6f},dimension:{lat:.6f}\"\n",
    "        \n",
    "        # 添加多模态信息块\n",
    "        prompt_part = (\n",
    "            f\"time:{time_label}\"\n",
    "            f\"gps:{gps_str}\"\n",
    "        )\n",
    "        prompt_parts.append(prompt_part)\n",
    "    \n",
    "    # 组合完整提示词\n",
    "    full_prompt = (\"\".join(prompt_parts))\n",
    "\n",
    "    # 提取所有视觉路径（RGB + 热力图）\n",
    "    all_image_paths = [p for pair in zip(video_paths, heatmap_paths) for p in pair]\n",
    "    \n",
    "    return {\n",
    "        \"prompt\": full_prompt,\n",
    "        \"image_paths\": all_image_paths,\n",
    "        \"labels\": sample['target_mmwave'].argmax(dim=-1).tolist()  # 假设索引是最大值位置\n",
    "    }\n",
    "\n",
    "# 示例使用 ---------------------------------------------------\n",
    "def process_sample(sample, processor):  # 添加processor参数\n",
    "    # Step 1: 构建提示词和获取图像路径\n",
    "    processed = build_prompt_and_inputs(sample)\n",
    "    \n",
    "    # Step 2: 构建messages结构\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"image\", \"image\": path} for path in processed[\"image_paths\"]] + \n",
    "                  [{\"type\": \"text\", \"text\": processed[\"prompt\"]}]\n",
    "    }]\n",
    "    \n",
    "    # Step 3: 使用传入的processor处理输入\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    return inputs, processed[\"labels\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39048644",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ffa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedVisionDataset(Dataset):\n",
    "    def __init__(self, original_dataset, processor):\n",
    "        self.cache = []\n",
    "        self.original_dataset = original_dataset  # 保存原始数据集引用\n",
    "        \n",
    "        # 预加载所有样本\n",
    "        for i in tqdm(range(len(original_dataset)), desc=\"Caching dataset\"):\n",
    "            sample = original_dataset[i]\n",
    "            try:\n",
    "                inputs, labels = process_sample(sample, processor)\n",
    "                # 将处理后的数据转移到CPU（避免占用GPU内存）\n",
    "                inputs = {k: v.cpu() for k, v in inputs.items()}\n",
    "                self.cache.append((inputs, labels))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing sample {i}: {e}\")\n",
    "                # 可以选择跳过错误样本或添加占位符\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集大小 - 这是必须实现的方法\"\"\"\n",
    "        return len(self.original_dataset)  # 或者 len(self.cache)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"直接返回缓存的处理结果\"\"\"\n",
    "        return self.cache[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c95078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n",
    "\n",
    "class QwenVisionDataset(Dataset):\n",
    "    def __init__(self, data_csv_paths, modal='mmwave_gps', input_length=8, output_length=3):\n",
    "        self.data_csv_paths = data_csv_paths\n",
    "        self.modal = modal\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        \n",
    "        # 特征列映射\n",
    "        self.features_column = {\n",
    "            # 'rgbs': 'unit1_rgb',\n",
    "            'rgbs': 'unit1_camera_resized',\n",
    "            'u1_loc': 'unit1_loc',\n",
    "            'u2_loc': 'unit2_loc',\n",
    "            'mmwave': 'unit1_pwr_60ghz',\n",
    "            'heatmap': 'unit1_mmwave_heatmap'  # 新增热力图列\n",
    "        }\n",
    "        \n",
    "        # 初始化滑动窗口\n",
    "        self.window_samples = []\n",
    "        for seq_idx, data_csv_path in enumerate(self.data_csv_paths):\n",
    "            data_csv = pd.read_csv(data_csv_path)\n",
    "            for seq_id in data_csv['seq_index'].unique():\n",
    "                seq_data = data_csv[data_csv['seq_index'] == seq_id]\n",
    "                if len(seq_data) >= self.input_length:\n",
    "                    for start_idx in range(len(seq_data) - self.input_length + 1):\n",
    "                        self.window_samples.append((seq_idx, seq_id, start_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx, seq_id, start_idx = self.window_samples[idx]\n",
    "        base_path = os.path.dirname(self.data_csv_paths[seq_idx])\n",
    "        data_csv = pd.read_csv(self.data_csv_paths[seq_idx])\n",
    "        seq_data = data_csv[data_csv['seq_index'] == seq_id]\n",
    "        \n",
    "        # 获取原始路径数据\n",
    "        window_data = {\n",
    "            'video_paths': \n",
    "            seq_data[self.features_column['rgbs']]\n",
    "            .iloc[start_idx:start_idx+self.input_length] \n",
    "            .tolist(),\n",
    "            'heatmap_paths': \n",
    "            seq_data[self.features_column['heatmap']]\n",
    "            .iloc[start_idx:start_idx+self.input_length] \n",
    "            .tolist()\n",
    "        }\n",
    "\n",
    "        # 处理GPS数据\n",
    "        gps = []\n",
    "        for i in range(self.input_length):\n",
    "            u1_loc = os.path.join(base_path, seq_data[self.features_column['u1_loc']].iloc[start_idx+i])\n",
    "            u2_loc = os.path.join(base_path, seq_data[self.features_column['u2_loc']].iloc[start_idx+i])\n",
    "            \n",
    "            with open(u1_loc, 'r') as f:\n",
    "                lat1, lon1 = map(float, f.read().strip().split())\n",
    "            with open(u2_loc, 'r') as f:\n",
    "                lat2, lon2 = map(float, f.read().strip().split())\n",
    "                \n",
    "            gps.append(torch.tensor([lat2-lat1, lon2-lon1], dtype=torch.float32))\n",
    "        gps = torch.stack(gps)\n",
    "\n",
    "        # 处理mmWave数据\n",
    "        mmwave = []\n",
    "        for i in range(self.input_length):\n",
    "            mmwave_path = os.path.join(base_path, \n",
    "                seq_data[self.features_column['mmwave']].iloc[start_idx+i])\n",
    "            with open(mmwave_path, 'r') as f:\n",
    "                mmwave.append(torch.tensor(\n",
    "                    list(map(float, f.read().strip().split())), \n",
    "                    dtype=torch.float32))\n",
    "        mmwave = torch.stack(mmwave)\n",
    "\n",
    "        # 目标数据（最后output_length个时间步）\n",
    "        target = []\n",
    "        for i in range(self.input_length-self.output_length, self.input_length):\n",
    "            mmwave_path = os.path.join(base_path,\n",
    "                seq_data[self.features_column['mmwave']].iloc[start_idx+i])\n",
    "            with open(mmwave_path, 'r') as f:\n",
    "                target.append(torch.tensor(\n",
    "                    list(map(float, f.read().strip().split())),\n",
    "                    dtype=torch.float32))\n",
    "        target = torch.stack(target)\n",
    "\n",
    "        return {\n",
    "            'video_paths': [os.path.join(base_path, p) for p in window_data['video_paths']],\n",
    "            'heatmap_paths': [os.path.join(base_path, p) for p in window_data['heatmap_paths']],\n",
    "            'gps': gps,\n",
    "            'mmwave': mmwave,\n",
    "            'target_mmwave': target\n",
    "        }\n",
    "\n",
    "def qwen_collate_fn(batch):\n",
    "    collated = {\n",
    "        'video_paths': [item['video_paths'] for item in batch],\n",
    "        'heatmap_paths': [item['heatmap_paths'] for item in batch],\n",
    "        'gps': pad_sequence([item['gps'] for item in batch], batch_first=True),\n",
    "        'mmwave': pad_sequence([item['mmwave'] for item in batch], batch_first=True),\n",
    "        'target_mmwave': pad_sequence([item['target_mmwave'] for item in batch], batch_first=True)\n",
    "    }\n",
    "    return collated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d3200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 CSV files for training.\n"
     ]
    }
   ],
   "source": [
    "dataset_start_idx = 1\n",
    "dataset_end_idx = 9\n",
    "# 定义数据集路径\n",
    "dataset_path = [f'/data2/wzj/Datasets/DeepSense/scenario{i}/' for i in range(dataset_start_idx, dataset_end_idx)]  # scenario1 ~ scenario8\n",
    "\n",
    "data_csv_paths = []\n",
    "for path in dataset_path:\n",
    "    data_csv_paths.extend(glob.glob(os.path.join(path, '*.csv')))\n",
    "\n",
    "print(f\"Found {len(data_csv_paths)} CSV files for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dbd2179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 每个 CSV 的行数 vs 窗口样本数 ===\n",
      "scenario1/scenario1.csv: rows = 2411, windows = 2208\n",
      "scenario2/scenario2.csv: rows = 2974, windows = 2736\n",
      "scenario3/scenario3.csv: rows = 1487, windows = 1123\n",
      "scenario4/scenario4.csv: rows = 1867, windows = 1363\n",
      "scenario5/scenario5.csv: rows = 2300, windows = 2097\n",
      "scenario6/scenario6.csv: rows = 915, windows = 831\n",
      "scenario7/scenario7.csv: rows = 854, windows = 430\n",
      "scenario8/scenario8.csv: rows = 4043, windows = 3462\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 正则提取场景和序列索引\n",
    "pattern_scen = re.compile(r'scenario(\\d+)')\n",
    "input_length = 8\n",
    "\n",
    "print(\"=== 每个 CSV 的行数 vs 窗口样本数 ===\")\n",
    "for csv_path in data_csv_paths:\n",
    "    # 1) 读表\n",
    "    df = pd.read_csv(csv_path)\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    # 2) 按 seq_index 统计窗口数\n",
    "    win_count = 0\n",
    "    for seq_id, grp in df.groupby('seq_index'):\n",
    "        L = len(grp)\n",
    "        if L >= input_length:\n",
    "            win_count += (L - input_length + 1)\n",
    "    \n",
    "    # 3) 输出\n",
    "    scen_match = pattern_scen.search(csv_path)\n",
    "    scen = scen_match.group(0) if scen_match else \"unknown\"\n",
    "    fname = os.path.basename(csv_path)\n",
    "    print(f\"{scen}/{fname}: rows = {total_rows}, windows = {win_count}\")\n",
    "print(\"====================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f7b41",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95a605cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_paths': ['/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5376_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5377_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5378_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5379_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5380_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5381_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5382_00_52_36.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/camera_resized/image_BS1_5383_00_52_36.jpg'],\n",
       " 'heatmap_paths': ['/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1075.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1076.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1077.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1078.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1079.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1080.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1081.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario1/./unit1/mmWave_heatmap/mmWave_power_1082.png'],\n",
       " 'gps': tensor([[2.3318e-05, 2.2738e-04],\n",
       "         [2.7988e-05, 2.2698e-04],\n",
       "         [3.2698e-05, 2.2658e-04],\n",
       "         [3.7458e-05, 2.2618e-04],\n",
       "         [4.2258e-05, 2.2588e-04],\n",
       "         [4.7098e-05, 2.2558e-04],\n",
       "         [5.1988e-05, 2.2518e-04],\n",
       "         [5.6918e-05, 2.2488e-04]]),\n",
       " 'mmwave': tensor([[0.0169, 0.0203, 0.0211, 0.0198, 0.0211, 0.0201, 0.0187, 0.0196, 0.0210,\n",
       "          0.0223, 0.0211, 0.0221, 0.0206, 0.0206, 0.0195, 0.0222, 0.0212, 0.0206,\n",
       "          0.0195, 0.0212, 0.0226, 0.0238, 0.0233, 0.0206, 0.0186, 0.0193, 0.0241,\n",
       "          0.0338, 0.0400, 0.0487, 0.0505, 0.0473, 0.0453, 0.0347, 0.0272, 0.0239,\n",
       "          0.0217, 0.0186, 0.0190, 0.0197, 0.0215, 0.0233, 0.0239, 0.0260, 0.0256,\n",
       "          0.0212, 0.0199, 0.0196, 0.0191, 0.0191, 0.0199, 0.0193, 0.0192, 0.0186,\n",
       "          0.0192, 0.0192, 0.0183, 0.0183, 0.0184, 0.0190, 0.0184, 0.0182, 0.0171,\n",
       "          0.0159],\n",
       "         [0.0174, 0.0222, 0.0234, 0.0222, 0.0207, 0.0207, 0.0210, 0.0219, 0.0258,\n",
       "          0.0254, 0.0245, 0.0235, 0.0219, 0.0225, 0.0219, 0.0272, 0.0271, 0.0217,\n",
       "          0.0239, 0.0263, 0.0375, 0.0365, 0.0293, 0.0235, 0.0219, 0.0240, 0.0423,\n",
       "          0.0815, 0.1052, 0.1008, 0.1143, 0.1066, 0.0822, 0.0552, 0.0324, 0.0234,\n",
       "          0.0199, 0.0204, 0.0236, 0.0273, 0.0257, 0.0286, 0.0346, 0.0332, 0.0322,\n",
       "          0.0234, 0.0208, 0.0206, 0.0223, 0.0239, 0.0257, 0.0225, 0.0222, 0.0208,\n",
       "          0.0217, 0.0227, 0.0217, 0.0199, 0.0191, 0.0224, 0.0216, 0.0199, 0.0185,\n",
       "          0.0163],\n",
       "         [0.0186, 0.0225, 0.0244, 0.0212, 0.0214, 0.0213, 0.0245, 0.0251, 0.0272,\n",
       "          0.0253, 0.0239, 0.0214, 0.0184, 0.0213, 0.0226, 0.0284, 0.0267, 0.0227,\n",
       "          0.0232, 0.0318, 0.0365, 0.0320, 0.0259, 0.0198, 0.0204, 0.0359, 0.0623,\n",
       "          0.1012, 0.1065, 0.0929, 0.0903, 0.0835, 0.0531, 0.0334, 0.0219, 0.0197,\n",
       "          0.0209, 0.0220, 0.0237, 0.0263, 0.0290, 0.0303, 0.0308, 0.0288, 0.0268,\n",
       "          0.0207, 0.0185, 0.0188, 0.0205, 0.0240, 0.0241, 0.0213, 0.0209, 0.0204,\n",
       "          0.0192, 0.0207, 0.0202, 0.0202, 0.0206, 0.0221, 0.0209, 0.0190, 0.0187,\n",
       "          0.0172],\n",
       "         [0.0184, 0.0218, 0.0214, 0.0197, 0.0225, 0.0263, 0.0285, 0.0309, 0.0290,\n",
       "          0.0241, 0.0215, 0.0195, 0.0185, 0.0244, 0.0266, 0.0298, 0.0326, 0.0228,\n",
       "          0.0275, 0.0320, 0.0305, 0.0257, 0.0222, 0.0200, 0.0270, 0.0518, 0.0799,\n",
       "          0.1019, 0.0933, 0.0828, 0.0704, 0.0567, 0.0351, 0.0226, 0.0194, 0.0188,\n",
       "          0.0228, 0.0268, 0.0269, 0.0296, 0.0321, 0.0330, 0.0290, 0.0249, 0.0204,\n",
       "          0.0191, 0.0193, 0.0190, 0.0207, 0.0223, 0.0220, 0.0203, 0.0211, 0.0201,\n",
       "          0.0192, 0.0189, 0.0181, 0.0193, 0.0196, 0.0205, 0.0204, 0.0193, 0.0178,\n",
       "          0.0169],\n",
       "         [0.0199, 0.0212, 0.0240, 0.0281, 0.0319, 0.0373, 0.0405, 0.0387, 0.0312,\n",
       "          0.0220, 0.0185, 0.0214, 0.0259, 0.0320, 0.0423, 0.0427, 0.0340, 0.0379,\n",
       "          0.0461, 0.0604, 0.0454, 0.0259, 0.0245, 0.0357, 0.0627, 0.1006, 0.1222,\n",
       "          0.1290, 0.1155, 0.0817, 0.0676, 0.0495, 0.0306, 0.0206, 0.0206, 0.0200,\n",
       "          0.0239, 0.0297, 0.0308, 0.0351, 0.0396, 0.0350, 0.0280, 0.0236, 0.0206,\n",
       "          0.0197, 0.0223, 0.0219, 0.0210, 0.0241, 0.0223, 0.0218, 0.0224, 0.0220,\n",
       "          0.0200, 0.0186, 0.0187, 0.0198, 0.0198, 0.0208, 0.0207, 0.0198, 0.0183,\n",
       "          0.0171],\n",
       "         [0.0203, 0.0224, 0.0240, 0.0318, 0.0294, 0.0274, 0.0281, 0.0237, 0.0215,\n",
       "          0.0191, 0.0185, 0.0190, 0.0210, 0.0222, 0.0276, 0.0288, 0.0263, 0.0256,\n",
       "          0.0293, 0.0349, 0.0236, 0.0219, 0.0314, 0.0448, 0.0755, 0.0939, 0.1082,\n",
       "          0.1029, 0.0792, 0.0563, 0.0406, 0.0329, 0.0243, 0.0190, 0.0209, 0.0220,\n",
       "          0.0253, 0.0331, 0.0358, 0.0373, 0.0343, 0.0313, 0.0238, 0.0202, 0.0203,\n",
       "          0.0202, 0.0231, 0.0212, 0.0206, 0.0227, 0.0209, 0.0205, 0.0216, 0.0221,\n",
       "          0.0206, 0.0191, 0.0191, 0.0193, 0.0194, 0.0188, 0.0192, 0.0220, 0.0199,\n",
       "          0.0172],\n",
       "         [0.0214, 0.0263, 0.0292, 0.0378, 0.0287, 0.0271, 0.0238, 0.0210, 0.0196,\n",
       "          0.0192, 0.0205, 0.0200, 0.0232, 0.0256, 0.0295, 0.0349, 0.0354, 0.0302,\n",
       "          0.0321, 0.0257, 0.0225, 0.0270, 0.0390, 0.0473, 0.0642, 0.0705, 0.0747,\n",
       "          0.0773, 0.0669, 0.0450, 0.0292, 0.0242, 0.0235, 0.0217, 0.0219, 0.0223,\n",
       "          0.0302, 0.0410, 0.0395, 0.0360, 0.0320, 0.0267, 0.0228, 0.0229, 0.0246,\n",
       "          0.0234, 0.0234, 0.0247, 0.0253, 0.0240, 0.0201, 0.0203, 0.0215, 0.0244,\n",
       "          0.0257, 0.0229, 0.0207, 0.0203, 0.0202, 0.0198, 0.0202, 0.0272, 0.0261,\n",
       "          0.0179],\n",
       "         [0.0187, 0.0213, 0.0252, 0.0245, 0.0210, 0.0208, 0.0181, 0.0176, 0.0189,\n",
       "          0.0221, 0.0206, 0.0197, 0.0229, 0.0271, 0.0302, 0.0290, 0.0282, 0.0239,\n",
       "          0.0192, 0.0184, 0.0286, 0.0496, 0.0654, 0.0738, 0.0865, 0.0931, 0.0866,\n",
       "          0.0636, 0.0463, 0.0302, 0.0224, 0.0211, 0.0243, 0.0270, 0.0373, 0.0356,\n",
       "          0.0529, 0.0608, 0.0455, 0.0315, 0.0258, 0.0227, 0.0208, 0.0240, 0.0285,\n",
       "          0.0224, 0.0211, 0.0230, 0.0223, 0.0202, 0.0187, 0.0184, 0.0189, 0.0205,\n",
       "          0.0219, 0.0215, 0.0191, 0.0192, 0.0198, 0.0219, 0.0216, 0.0232, 0.0223,\n",
       "          0.0169]]),\n",
       " 'target_mmwave': tensor([[0.0203, 0.0224, 0.0240, 0.0318, 0.0294, 0.0274, 0.0281, 0.0237, 0.0215,\n",
       "          0.0191, 0.0185, 0.0190, 0.0210, 0.0222, 0.0276, 0.0288, 0.0263, 0.0256,\n",
       "          0.0293, 0.0349, 0.0236, 0.0219, 0.0314, 0.0448, 0.0755, 0.0939, 0.1082,\n",
       "          0.1029, 0.0792, 0.0563, 0.0406, 0.0329, 0.0243, 0.0190, 0.0209, 0.0220,\n",
       "          0.0253, 0.0331, 0.0358, 0.0373, 0.0343, 0.0313, 0.0238, 0.0202, 0.0203,\n",
       "          0.0202, 0.0231, 0.0212, 0.0206, 0.0227, 0.0209, 0.0205, 0.0216, 0.0221,\n",
       "          0.0206, 0.0191, 0.0191, 0.0193, 0.0194, 0.0188, 0.0192, 0.0220, 0.0199,\n",
       "          0.0172],\n",
       "         [0.0214, 0.0263, 0.0292, 0.0378, 0.0287, 0.0271, 0.0238, 0.0210, 0.0196,\n",
       "          0.0192, 0.0205, 0.0200, 0.0232, 0.0256, 0.0295, 0.0349, 0.0354, 0.0302,\n",
       "          0.0321, 0.0257, 0.0225, 0.0270, 0.0390, 0.0473, 0.0642, 0.0705, 0.0747,\n",
       "          0.0773, 0.0669, 0.0450, 0.0292, 0.0242, 0.0235, 0.0217, 0.0219, 0.0223,\n",
       "          0.0302, 0.0410, 0.0395, 0.0360, 0.0320, 0.0267, 0.0228, 0.0229, 0.0246,\n",
       "          0.0234, 0.0234, 0.0247, 0.0253, 0.0240, 0.0201, 0.0203, 0.0215, 0.0244,\n",
       "          0.0257, 0.0229, 0.0207, 0.0203, 0.0202, 0.0198, 0.0202, 0.0272, 0.0261,\n",
       "          0.0179],\n",
       "         [0.0187, 0.0213, 0.0252, 0.0245, 0.0210, 0.0208, 0.0181, 0.0176, 0.0189,\n",
       "          0.0221, 0.0206, 0.0197, 0.0229, 0.0271, 0.0302, 0.0290, 0.0282, 0.0239,\n",
       "          0.0192, 0.0184, 0.0286, 0.0496, 0.0654, 0.0738, 0.0865, 0.0931, 0.0866,\n",
       "          0.0636, 0.0463, 0.0302, 0.0224, 0.0211, 0.0243, 0.0270, 0.0373, 0.0356,\n",
       "          0.0529, 0.0608, 0.0455, 0.0315, 0.0258, 0.0227, 0.0208, 0.0240, 0.0285,\n",
       "          0.0224, 0.0211, 0.0230, 0.0223, 0.0202, 0.0187, 0.0184, 0.0189, 0.0205,\n",
       "          0.0219, 0.0215, 0.0191, 0.0192, 0.0198, 0.0219, 0.0216, 0.0232, 0.0223,\n",
       "          0.0169]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset = QwenVisionDataset(\n",
    "    data_csv_paths,\n",
    "    input_length=8,\n",
    "    output_length=3\n",
    ")\n",
    "original_dataset[998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99fdb023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分结果:\n",
      "  总样本数: 4000\n",
      "  训练集: 3200 样本 (80.0%)\n",
      "  验证集: 400 样本 (10.0%)\n",
      "  测试集: 400 样本 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "random.seed(42)\n",
    "\n",
    "# 定义要抽取的总样本数量\n",
    "total_samples = 4000  # 你可以根据需要调整这个数字\n",
    "\n",
    "# 获取原始数据集的样本总数\n",
    "total_dataset_size = len(original_dataset)\n",
    "\n",
    "# 确保抽取的样本数不超过数据集大小\n",
    "if total_samples > total_dataset_size:\n",
    "    print(f\"警告：要求抽取 {total_samples} 个样本，但数据集只有 {total_dataset_size} 个样本。将使用全部样本。\")\n",
    "    total_samples = total_dataset_size\n",
    "\n",
    "# 随机抽取指定数量的样本索引\n",
    "all_indices = list(range(total_dataset_size))\n",
    "chosen_indices = random.sample(all_indices, total_samples)\n",
    "\n",
    "# 将抽取的样本按80/10/10拆分为训练集、验证集和测试集\n",
    "random.shuffle(chosen_indices)  # 再次打乱确保随机性\n",
    "n = len(chosen_indices)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "\n",
    "train_indices = chosen_indices[:n_train]\n",
    "val_indices = chosen_indices[n_train:n_train + n_val]\n",
    "test_indices = chosen_indices[n_train + n_val:]\n",
    "\n",
    "# 创建最终的数据集\n",
    "train_dataset = Subset(original_dataset, train_indices)\n",
    "val_dataset = Subset(original_dataset, val_indices)\n",
    "test_dataset = Subset(original_dataset, test_indices)\n",
    "\n",
    "print(\"数据集划分结果:\")\n",
    "print(f\"  总样本数: {total_samples}\")\n",
    "print(f\"  训练集: {len(train_dataset)} 样本 ({len(train_dataset)/total_samples*100:.1f}%)\")\n",
    "print(f\"  验证集: {len(val_dataset)} 样本 ({len(val_dataset)/total_samples*100:.1f}%)\")\n",
    "print(f\"  测试集: {len(test_dataset)} 样本 ({len(test_dataset)/total_samples*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a298b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train 集合场景分布 ---\n",
      "scenario1: 478\n",
      "scenario2: 602\n",
      "scenario3: 247\n",
      "scenario4: 321\n",
      "scenario5: 476\n",
      "scenario6: 178\n",
      "scenario7: 119\n",
      "scenario8: 779\n",
      "\n",
      "--- Val 集合场景分布 ---\n",
      "scenario1: 68\n",
      "scenario2: 85\n",
      "scenario3: 30\n",
      "scenario4: 43\n",
      "scenario5: 52\n",
      "scenario6: 25\n",
      "scenario7: 14\n",
      "scenario8: 83\n",
      "\n",
      "--- Test 集合场景分布 ---\n",
      "scenario1: 62\n",
      "scenario2: 70\n",
      "scenario3: 33\n",
      "scenario4: 33\n",
      "scenario5: 68\n",
      "scenario6: 17\n",
      "scenario7: 11\n",
      "scenario8: 106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# 先重现一份 scenario_of_sample 的映射（同采样脚本中做法）\n",
    "pattern = re.compile(r'scenario(\\d+)')\n",
    "scenario_of_sample = []\n",
    "for seq_idx, seq_id, start_idx in original_dataset.window_samples:\n",
    "    csv_path = original_dataset.data_csv_paths[seq_idx]\n",
    "    m = pattern.search(csv_path)\n",
    "    scenario_of_sample.append(f\"scenario{m.group(1)}\" if m else \"unknown\")\n",
    "\n",
    "# 定义一个函数统计\n",
    "def print_distribution(indices, name):\n",
    "    cnt = Counter(scenario_of_sample[i] for i in indices)\n",
    "    print(f\"--- {name} 集合场景分布 ---\")\n",
    "    for scen in sorted(cnt.keys(), key=lambda x: int(x.replace('scenario',''))):\n",
    "        print(f\"{scen}: {cnt[scen]}\")\n",
    "    print()\n",
    "\n",
    "# 拿到各子集对应的原始索引\n",
    "train_idx = train_dataset.indices if hasattr(train_dataset, 'indices') else train_dataset.dataset_indices\n",
    "val_idx   = val_dataset.indices   if hasattr(val_dataset,   'indices') else val_dataset.dataset_indices\n",
    "test_idx  = test_dataset.indices  if hasattr(test_dataset,  'indices') else test_dataset.dataset_indices\n",
    "\n",
    "# 打印分布\n",
    "print_distribution(train_idx, 'Train')\n",
    "print_distribution(val_idx,   'Val')\n",
    "print_distribution(test_idx,  'Test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa4e860",
   "metadata": {},
   "source": [
    "### 划分数据集（抽出1600个样本微调）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "febef180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom torch.utils.data import Subset\\nimport random\\n\\n# 固定随机种子确保每次结果一致（可选）\\nrandom.seed(42)\\n\\n# 原始数据集有约 14400 个样本\\ntotal_samples = len(original_dataset)\\n\\n# 随机选出 1600 个样本的索引\\nsubset_indices = random.sample(range(total_samples), 160)\\n\\n# 创建新的 dataset\\nsmall_dataset = Subset(original_dataset, subset_indices)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "# 固定随机种子确保每次结果一致（可选）\n",
    "random.seed(42)\n",
    "\n",
    "# 原始数据集有约 14400 个样本\n",
    "total_samples = len(original_dataset)\n",
    "\n",
    "# 随机选出 1600 个样本的索引\n",
    "subset_indices = random.sample(range(total_samples), 160)\n",
    "\n",
    "# 创建新的 dataset\n",
    "small_dataset = Subset(original_dataset, subset_indices)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6813b67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_size = int(0.8 * len(small_dataset))\\nval_size = int(0.1 * len(small_dataset))\\ntest_size = len(small_dataset) - train_size - val_size\\ntrain_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\\n\\nprint(f\"Total Training samples: {len(train_dataset)}\")\\nprint(f\"Total Validation samples: {len(val_dataset)}\")\\nprint(f\"Total Testing samples: {len(test_dataset)}\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_size = int(0.8 * len(small_dataset))\n",
    "val_size = int(0.1 * len(small_dataset))\n",
    "test_size = len(small_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "print(f\"Total Training samples: {len(train_dataset)}\")\n",
    "print(f\"Total Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Total Testing samples: {len(test_dataset)}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae7f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching dataset: 100%|██████████| 3200/3200 [02:20<00:00, 22.76it/s]\n",
      "Caching dataset: 100%|██████████| 400/400 [00:17<00:00, 22.73it/s]\n",
      "Caching dataset: 100%|██████████| 400/400 [00:18<00:00, 21.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# 创建缓存数据集（在训练前一次性处理）\n",
    "cached_train = CachedVisionDataset(train_dataset, processor)\n",
    "cached_val = CachedVisionDataset(val_dataset, processor)\n",
    "cached_test = CachedVisionDataset(test_dataset, processor)\n",
    "# 修改DataLoader使用新collate函数\n",
    "def collate_fn(batch, device):\n",
    "    \"\"\"处理缓存数据的批处理\"\"\"\n",
    "    batch_inputs = {\"input_ids\": [], \"attention_mask\": [], \"pixel_values\": [], \"image_grid_thw\": []}\n",
    "    batch_labels = []\n",
    "    \n",
    "    for (inputs, labels) in batch:\n",
    "        batch_inputs[\"input_ids\"].append(inputs[\"input_ids\"])\n",
    "        batch_inputs[\"attention_mask\"].append(inputs[\"attention_mask\"])\n",
    "        batch_inputs[\"pixel_values\"].append(inputs[\"pixel_values\"])\n",
    "        batch_inputs[\"image_grid_thw\"].append(inputs[\"image_grid_thw\"])\n",
    "        batch_labels.append(labels)\n",
    "    \n",
    "    # 拼接张量（保持在CPU）\n",
    "    batch_inputs = {\n",
    "        \"input_ids\": torch.cat(batch_inputs[\"input_ids\"], dim=0),\n",
    "        \"attention_mask\": torch.cat(batch_inputs[\"attention_mask\"], dim=0),\n",
    "        \"pixel_values\": torch.cat(batch_inputs[\"pixel_values\"], dim=0),\n",
    "        \"image_grid_thw\": torch.cat(batch_inputs[\"image_grid_thw\"], dim=0)\n",
    "    }\n",
    "    batch_labels = torch.tensor(batch_labels, dtype=torch.long)\n",
    "    \n",
    "    return batch_inputs, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8309968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 0.00 GB\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 1                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    cached_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=partial(collate_fn, device=\"cpu\"),  # 绑定设备参数\n",
    "    pin_memory=True if device.type == \"cuda\" else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    cached_val, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  \n",
    "    collate_fn=partial(collate_fn, device=\"cpu\"),\n",
    "    pin_memory=True if device.type == \"cuda\" else False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    cached_test, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,  \n",
    "    collate_fn=partial(collate_fn, device=\"cpu\"),\n",
    "    pin_memory=True if device.type == \"cuda\" else False\n",
    ")\n",
    "print(f\"Memory usage: {torch.cuda.memory_allocated(device=device)/1024**3:.2f} GB\")\n",
    "print(torch.cuda.memory_summary(device=device, abbreviated=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90d4c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 输入数据 ===\n",
      "Input IDs 形状: torch.Size([1, 482])\n",
      "Attention Mask 形状: torch.Size([1, 482])\n",
      "Pixel Values 形状: torch.Size([1220, 1176])\n",
      "Image Grid THW: tensor([[ 1, 10, 18],\n",
      "        [ 1,  8,  8],\n",
      "        [ 1, 10, 18],\n",
      "        [ 1,  8,  8],\n",
      "        [ 1, 10, 18],\n",
      "        [ 1,  8,  8],\n",
      "        [ 1, 10, 18],\n",
      "        [ 1,  8,  8],\n",
      "        [ 1, 10, 18],\n",
      "        [ 1,  8,  8]])\n",
      "\n",
      "=== 标签数据 ===\n",
      "标签: [25, 25, 25]\n"
     ]
    }
   ],
   "source": [
    "# 查看第一个训练样本\n",
    "sample_idx = 0\n",
    "inputs, labels = cached_train[sample_idx]\n",
    "\n",
    "print(\"=== 输入数据 ===\")\n",
    "print(f\"Input IDs 形状: {inputs['input_ids'].shape}\")  # (1, 序列长度)\n",
    "print(f\"Attention Mask 形状: {inputs['attention_mask'].shape}\")\n",
    "print(f\"Pixel Values 形状: {inputs['pixel_values'].shape}\")  # (1, 通道, 高, 宽)\n",
    "print(f\"Image Grid THW: {inputs['image_grid_thw']}\")\n",
    "\n",
    "print(\"\\n=== 标签数据 ===\")\n",
    "print(f\"标签: {labels}\")  # 例如 [23, 15, 42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712a0a4",
   "metadata": {},
   "source": [
    "## Model\n",
    "### 用Qwen构造带有输出投影模块的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2bc543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class QwenTimeLLMPlaceholderHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 qwen_model: nn.Module,\n",
    "                 pred_len: int = 3,        # 未来要预测的时刻数 P（占位符个数）\n",
    "                 num_beams: int = 64,      # 输出每个位置的分类数 C\n",
    "                 hidden_dim: int = 3584,   # Qwen 模型的隐藏维度 D\n",
    "                 proj_hidden: int = 2048,  # MLP 第一层隐藏维度\n",
    "                 dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        qwen_model: 预先加载好的 Qwen2.5-VLForConditionalGeneration 实例\n",
    "                    它包含 embedding 层 + 多层 Transformer Body + generation head。\n",
    "                    我们把它当作“冻结骨干”，只调用它做一次前向。\n",
    "        pred_len:   要补入的占位符数，也是未来要预测的 patch 数目 P（这里 3）\n",
    "        num_beams:  每个未来时刻要输出的类别数 C（这里 64）\n",
    "        hidden_dim: Qwen 模型最终 hidden size D（Qwen2.5-VL 为 3584）\n",
    "        proj_hidden:MLP 第一层的隐藏单元数\n",
    "        dropout:    MLP 中使用的 dropout 比例\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1) 保存并冻结 Qwen 主干\n",
    "        self.qwen = qwen_model\n",
    "        self.qwen.gradient_checkpointing_enable()\n",
    "        for p in self.qwen.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # 2) 定义 P 个可训练的占位符 Embedding (P × D)\n",
    "        self.P = pred_len\n",
    "        self.D = hidden_dim\n",
    "        self.patch_init = nn.Parameter(torch.randn(self.P, self.D))\n",
    "\n",
    "        # 3) 定义最后的分类 Head：先把 (B, P, D) flatten→(B*P, D)→MLP→(B*P, C)→reshape→(B, P, C)\n",
    "        self.num_beams = num_beams\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.D, proj_hidden),  # D -> proj_hidden\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(proj_hidden, self.num_beams)  # proj_hidden -> C\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids: torch.LongTensor,\n",
    "                attention_mask: torch.LongTensor,\n",
    "                pixel_values: torch.FloatTensor,\n",
    "                image_grid_thw: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          input_ids:       (B, L_text)         来自 Qwen Processor 的文本 token IDs\n",
    "          attention_mask:  (B, L_text)         对应的文本 mask\n",
    "          pixel_values:    (B, C, H, W)        来自 Processor 的图像张量\n",
    "          image_grid_thw:  (B, N_patches, 3)   Qwen VL 需要的 patch/grid 形状信息\n",
    "\n",
    "        Returns:\n",
    "          logits: (B, P, C)  → (B, 3, 64)，“未来 3 步，每步 64 类”的 logits\n",
    "        \"\"\"\n",
    "        B = input_ids.size(0)\n",
    "        device = input_ids.device\n",
    "\n",
    "        # ——————————————————————\n",
    "        # A. 用 Qwen 的 embedding 层把 input_ids 转为 input_embeds: (B, L_text, D)\n",
    "        # ——————————————————————\n",
    "        # Qwen2_5_VLForConditionalGeneration 一般有 get_input_embeddings() 接口\n",
    "        input_embeds = self.qwen.get_input_embeddings()(input_ids)  # (B, L_text, D)\n",
    "\n",
    "        # ——————————————————————\n",
    "        # B. 在 input_embeds 后面按 dim=1 拼接 P 个占位符： new_embeds (B, L_text + P, D)\n",
    "        # ——————————————————————\n",
    "        # patch_init: (P, D) -> (1, P, D) -> expand(B, P, D)\n",
    "        output_queries = self.patch_init.unsqueeze(0).expand(B, -1, -1)  # (B, P, D)\n",
    "        new_embeds = torch.cat([input_embeds, output_queries], dim=1)   # (B, L+P, D)\n",
    "\n",
    "        # ——————————————————————\n",
    "        # C. 拼接新的 attention_mask: (B, L_text + P)\n",
    "        #    对应原来的文本 mask，再加 P 个全 1，表示占位符也要被注意力看到\n",
    "        # ——————————————————————\n",
    "        placeholder_mask = torch.ones(B, self.P, device=device, dtype=attention_mask.dtype)\n",
    "        new_attention_mask = torch.cat([attention_mask, placeholder_mask], dim=1)  # (B, L+P)\n",
    "\n",
    "        # ——————————————————————\n",
    "        # D. 把 new_embeds、new_attention_mask、pixel_values、image_grid_thw\n",
    "        #    一起送给 Qwen Transformer Body，拿到 hidden_states: (B, L+P, D)\n",
    "        #\n",
    "        #   注意：我们假设 Qwen2_5_VLForConditionalGeneration 支持\n",
    "        #         inputs_embeds=new_embeds, attention_mask=new_attention_mask,\n",
    "        #         pixel_values=pixel_values, image_grid_thw=image_grid_thw\n",
    "        #         并且返回 last_hidden_state\n",
    "        # ——————————————————————\n",
    "        outputs = self.qwen(\n",
    "            inputs_embeds=new_embeds,           # (B, L+P, D)\n",
    "            attention_mask=new_attention_mask,   # (B, L+P)\n",
    "            pixel_values=pixel_values,           # (B, C, H, W)\n",
    "            image_grid_thw=image_grid_thw,       # (B, N_patches, 3)\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states[-1] # (B, L+P, D)\n",
    "\n",
    "        # ——————————————————————\n",
    "        # E. 从 hidden_states 取最后 P=3 个位置，作为 “Output Patch Embeddings”: (B, P, D)\n",
    "        # ——————————————————————\n",
    "        future_patch_emb = hidden_states[:, -self.P:, :]  # (B, P, D)\n",
    "\n",
    "        # ——————————————————————\n",
    "        # F. 把 (B, P, D) → dropout → flatten (B*P, D) → classifier → (B*P, C) → reshape (B, P, C)\n",
    "        # ——————————————————————\n",
    "        future_patch_emb = self.dropout(future_patch_emb)       # (B, P, D)\n",
    "        flat = future_patch_emb.contiguous().view(B * self.P, self.D)  # (B*P, D)\n",
    "        logits_flat = self.classifier(flat)                       # (B*P, C)\n",
    "        logits = logits_flat.view(B, self.P, self.num_beams)      # (B, P, 64)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b7894",
   "metadata": {},
   "source": [
    "### 加载Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30343410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:51:51,903 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /data2/dzr/.cache/models/Qwen/Qwen2.5-VL-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:51:52,266 - modelscope - INFO - Target directory already exists, skipping creation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c096ab33b80e4fa693b12dc262776691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "Memory usage: 15.49 GB\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 1                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  15865 MiB |  15865 MiB |  15865 MiB |      0 B   |\n",
      "|       from large pool |  15863 MiB |  15863 MiB |  15863 MiB |      0 B   |\n",
      "|       from small pool |      1 MiB |      1 MiB |      1 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  15865 MiB |  15865 MiB |  15865 MiB |      0 B   |\n",
      "|       from large pool |  15863 MiB |  15863 MiB |  15863 MiB |      0 B   |\n",
      "|       from small pool |      1 MiB |      1 MiB |      1 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  15816 MiB |  15816 MiB |  15816 MiB |      0 B   |\n",
      "|       from large pool |  15814 MiB |  15814 MiB |  15814 MiB |      0 B   |\n",
      "|       from small pool |      1 MiB |      1 MiB |      1 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  16064 MiB |  16064 MiB |  16064 MiB |      0 B   |\n",
      "|       from large pool |  16062 MiB |  16062 MiB |  16062 MiB |      0 B   |\n",
      "|       from small pool |      2 MiB |      2 MiB |      2 MiB |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 203226 KiB | 205298 KiB |   1030 MiB |    831 MiB |\n",
      "|       from large pool | 202872 KiB | 204920 KiB |   1028 MiB |    830 MiB |\n",
      "|       from small pool |    354 KiB |   2047 KiB |      1 MiB |      1 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     759    |     759    |     759    |       0    |\n",
      "|       from large pool |     361    |     361    |     361    |       0    |\n",
      "|       from small pool |     398    |     398    |     398    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     759    |     759    |     759    |       0    |\n",
      "|       from large pool |     361    |     361    |     361    |       0    |\n",
      "|       from small pool |     398    |     398    |     398    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     221    |     221    |     221    |       0    |\n",
      "|       from large pool |     220    |     220    |     220    |       0    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     102    |     102    |     133    |      31    |\n",
      "|       from large pool |     101    |     101    |     132    |      31    |\n",
      "|       from small pool |       1    |       1    |       1    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 配置 bfloat16 精度\n",
    "qwenbf16_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_ckpt,\n",
    "    torch_dtype=torch.bfloat16,    # 设置模型权重为 bfloat16\n",
    "    trust_remote_code=True,         # 必须开启\n",
    "    return_dict=True\n",
    ").to(device)\n",
    "print(device)\n",
    "print(f\"Memory usage: {torch.cuda.memory_allocated(device=device)/1024**3:.2f} GB\")\n",
    "print(torch.cuda.memory_summary(device=device, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22cd9bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2_5_VLForConditionalGeneration(\n",
      "  (model): Qwen2_5_VLModel(\n",
      "    (visual): Qwen2_5_VisionTransformerPretrainedModel(\n",
      "      (patch_embed): Qwen2_5_VisionPatchEmbed(\n",
      "        (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
      "      )\n",
      "      (rotary_pos_emb): Qwen2_5_VisionRotaryEmbedding()\n",
      "      (blocks): ModuleList(\n",
      "        (0-31): 32 x Qwen2_5_VLVisionBlock(\n",
      "          (norm1): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "          (norm2): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "          (attn): Qwen2_5_VLVisionSdpaAttention(\n",
      "            (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
      "            (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          )\n",
      "          (mlp): Qwen2_5_VLMLP(\n",
      "            (gate_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "            (up_proj): Linear(in_features=1280, out_features=3420, bias=True)\n",
      "            (down_proj): Linear(in_features=3420, out_features=1280, bias=True)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (merger): Qwen2_5_VLPatchMerger(\n",
      "        (ln_q): Qwen2RMSNorm((1280,), eps=1e-06)\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=5120, out_features=5120, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=5120, out_features=3584, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (language_model): Qwen2_5_VLTextModel(\n",
      "      (embed_tokens): Embedding(152064, 3584)\n",
      "      (layers): ModuleList(\n",
      "        (0-27): 28 x Qwen2_5_VLDecoderLayer(\n",
      "          (self_attn): Qwen2_5_VLSdpaAttention(\n",
      "            (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
      "            (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "            (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
      "            (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
      "            (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "          )\n",
      "          (mlp): Qwen2MLP(\n",
      "            (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "            (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
      "            (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "          (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "          (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
      "      (rotary_emb): Qwen2_5_VLRotaryEmbedding()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(qwenbf16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5841febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QwenTimeLLMPlaceholderHead(\n",
    "    qwen_model=qwenbf16_model,\n",
    "    pred_len=3,\n",
    "    num_beams=64,\n",
    "    hidden_dim=3584,\n",
    "    proj_hidden=2048,\n",
    "    dropout=0.1\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc9df97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scaler, device, accumulation_steps):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct_1 = 0\n",
    "    optimizer.zero_grad()\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        # inputs already dict of input_ids, attention_mask, pixel_values, image_grid_thw\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)                     # [B, P]\n",
    "\n",
    "        with autocast(dtype=torch.bfloat16):\n",
    "            logits = model(**inputs)                   # [B, 3, 64]\n",
    "            loss   = criterion(logits, labels)\n",
    "\n",
    "        scaler.scale(loss / accumulation_steps).backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct_1 += calculate_accuracy(logits, labels, k=1)\n",
    "\n",
    "    train_acc1 = total_correct_1 / len(train_loader)\n",
    "    avg_loss = total_loss / (len(train_loader) / accumulation_steps)\n",
    "    return avg_loss, train_acc1\n",
    "\n",
    "# 3. 验证函数同理\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = total_correct_1 = total_correct_3 = total_correct_5 = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "            with autocast(dtype=torch.bfloat16):\n",
    "                logits = model(**inputs)\n",
    "                loss   = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct_1 += calculate_accuracy(logits, labels, k=1)\n",
    "            total_correct_3 += calculate_accuracy(logits, labels, k=3)\n",
    "            total_correct_5 += calculate_accuracy(logits, labels, k=5)\n",
    "\n",
    "    n = len(val_loader)\n",
    "    return (total_loss / n,\n",
    "            total_correct_1 / n,\n",
    "            total_correct_3 / n,\n",
    "            total_correct_5 / n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e4e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 7483968\n"
     ]
    }
   ],
   "source": [
    "total_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Trainable params:\", total_trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e7f54",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaeb6c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70011/3122921442.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "patience  = 5\n",
    "checkpoint_dir = \"/data2/dzr/finetune/train_timellm_checkpoints\"\n",
    "accumulation_steps = 1\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "criterion = HybridLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4, weight_decay=1e-2\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5, \n",
    "    patience=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c512dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 15.52 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage: {torch.cuda.memory_allocated(device=device)/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f9cb3c",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217077e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_test_loss ,train_test_acc1 = train_epoch(\\n    model,  \\n    train_loader, \\n    criterion, \\n    optimizer, \\n    scaler, \\n    device, \\n    accumulation_steps\\n)\\nprint(f\"Train Loss: {train_test_loss:.4f}\")\\nprint(f\"Train Acc1: {train_test_acc1:.4f}\")\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_test_loss ,train_test_acc1 = train_epoch(\n",
    "    model,  \n",
    "    train_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scaler, \n",
    "    device, \n",
    "    accumulation_steps\n",
    ")\n",
    "print(f\"Train Loss: {train_test_loss:.4f}\")\n",
    "print(f\"Train Acc1: {train_test_acc1:.4f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630fb03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5c4187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_inline import backend_inline\n",
    "from IPython import display\n",
    "# 定义 use_svg_display 函数\n",
    "def use_svg_display():\n",
    "    \"\"\"Use the svg format to display a plot in Jupyter.\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# 定义 set_axes 函数\n",
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    \"\"\"设置 Matplotlib 的轴\"\"\"\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()\n",
    " \n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 3.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        use_svg_display()   \n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: set_axes(\n",
    "            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "\n",
    "    def show(self):\n",
    "        display.display(self.fig)# 输出图像\n",
    "        display.clear_output(wait=True)# 不输出新图像，而是覆盖之前的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36c3e9",
   "metadata": {},
   "source": [
    "## 恢复训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a4a4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, starting new training\n"
     ]
    }
   ],
   "source": [
    "# 恢复训练状态 - 针对只保存模型参数的检查点\n",
    "resume_checkpoint_path = '/data2/dzr/finetune/train_timellm_checkpoints/multimodal_encoder_decoder_best.pth'  # 替换为你的checkpoint路径\n",
    "\n",
    "if os.path.exists(resume_checkpoint_path):\n",
    "    print(f\"Loading model weights from {resume_checkpoint_path}\")\n",
    "    \n",
    "    # 加载模型参数\n",
    "    model.load_state_dict(torch.load(resume_checkpoint_path))\n",
    "    \n",
    "    # 由于只保存了模型参数，其他状态需要手动设置或重新初始化\n",
    "    start_epoch = 17  # 需要你手动设置起始epoch（根据中断时的epoch）\n",
    "    best_val_loss = float('inf')  # 重新初始化最佳验证损失\n",
    "    early_stop_counter = 5  # 重置早停计数器\n",
    "    elapsed_time_before = 0  # 重置已训练时间\n",
    "    \n",
    "    print(f\"Resuming training from epoch {start_epoch} (model weights only)\")\n",
    "else:\n",
    "    print(\"No checkpoint found, starting new training\")\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    elapsed_time_before = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f57c3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 15.52 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Memory usage: {torch.cuda.memory_allocated(device=device)/1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6a40af",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85f0ee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"235.7875pt\" height=\"242.595469pt\" viewBox=\"0 0 235.7875 242.595469\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-06-02T06:42:32.302408</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 242.595469 \n",
       "L 235.7875 242.595469 \n",
       "L 235.7875 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 205.039219 \n",
       "L 222.225 205.039219 \n",
       "L 222.225 10.999219 \n",
       "L 26.925 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 62.796429 205.039219 \n",
       "L 62.796429 10.999219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"mb7fb40715b\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb7fb40715b\" x=\"62.796429\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(56.433929 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 102.653571 205.039219 \n",
       "L 102.653571 10.999219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb7fb40715b\" x=\"102.653571\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(96.291071 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 142.510714 205.039219 \n",
       "L 142.510714 10.999219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb7fb40715b\" x=\"142.510714\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(136.148214 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 182.367857 205.039219 \n",
       "L 182.367857 10.999219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb7fb40715b\" x=\"182.367857\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(176.005357 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 222.225 205.039219 \n",
       "L 222.225 10.999219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mb7fb40715b\" x=\"222.225\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(215.8625 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(109.346875 233.315781) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(61.523438 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(125 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(186.181641 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(241.162109 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 26.925 205.039219 \n",
       "L 222.225 205.039219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m049bb4f2ae\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m049bb4f2ae\" x=\"26.925\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 208.838437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 26.925 166.231219 \n",
       "L 222.225 166.231219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m049bb4f2ae\" x=\"26.925\" y=\"166.231219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(13.5625 170.030437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 26.925 127.423219 \n",
       "L 222.225 127.423219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m049bb4f2ae\" x=\"26.925\" y=\"127.423219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(13.5625 131.222437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 26.925 88.615219 \n",
       "L 222.225 88.615219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m049bb4f2ae\" x=\"26.925\" y=\"88.615219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(13.5625 92.414437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 26.925 49.807219 \n",
       "L 222.225 49.807219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m049bb4f2ae\" x=\"26.925\" y=\"49.807219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 8 -->\n",
       "      <g transform=\"translate(13.5625 53.606437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 26.925 10.999219 \n",
       "L 222.225 10.999219 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m049bb4f2ae\" x=\"26.925\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 14.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_23\">\n",
       "    <path d=\"M 26.925 140.632408 \n",
       "L 30.910714 142.53203 \n",
       "L 34.896429 143.652001 \n",
       "L 38.882143 144.355918 \n",
       "L 42.867857 144.938023 \n",
       "L 46.853571 145.817621 \n",
       "L 50.839286 146.408697 \n",
       "L 54.825 146.503058 \n",
       "L 58.810714 146.927466 \n",
       "L 62.796429 147.294173 \n",
       "L 66.782143 147.513374 \n",
       "L 70.767857 147.998735 \n",
       "L 74.753571 147.88919 \n",
       "L 78.739286 148.34512 \n",
       "L 82.725 148.522933 \n",
       "L 86.710714 148.622122 \n",
       "L 90.696429 148.969014 \n",
       "L 94.682143 149.04775 \n",
       "L 98.667857 149.233973 \n",
       "L 102.653571 149.325015 \n",
       "L 106.639286 149.464311 \n",
       "L 110.625 149.555569 \n",
       "L 114.610714 150.004144 \n",
       "L 118.596429 150.289545 \n",
       "L 122.582143 150.55424 \n",
       "L 126.567857 150.53084 \n",
       "L 130.553571 150.644095 \n",
       "L 134.539286 150.623528 \n",
       "L 138.525 150.786653 \n",
       "L 142.510714 150.855825 \n",
       "L 146.496429 151.086406 \n",
       "L 150.482143 150.91329 \n",
       "L 154.467857 151.043393 \n",
       "L 158.453571 151.329286 \n",
       "L 162.439286 151.122284 \n",
       "L 166.425 151.157178 \n",
       "L 170.410714 151.410188 \n",
       "L 174.396429 151.524066 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_24\">\n",
       "    <path d=\"M 26.925 143.201624 \n",
       "L 30.910714 143.911293 \n",
       "L 34.896429 144.927287 \n",
       "L 38.882143 144.371106 \n",
       "L 42.867857 146.646999 \n",
       "L 46.853571 146.108421 \n",
       "L 50.839286 147.02773 \n",
       "L 54.825 147.257221 \n",
       "L 58.810714 147.963923 \n",
       "L 62.796429 147.941015 \n",
       "L 66.782143 147.685381 \n",
       "L 70.767857 147.608288 \n",
       "L 74.753571 148.612483 \n",
       "L 78.739286 148.259317 \n",
       "L 82.725 147.42905 \n",
       "L 86.710714 149.302233 \n",
       "L 90.696429 148.652433 \n",
       "L 94.682143 148.709891 \n",
       "L 98.667857 149.333987 \n",
       "L 102.653571 148.885566 \n",
       "L 106.639286 149.248387 \n",
       "L 110.625 148.440158 \n",
       "L 114.610714 149.330738 \n",
       "L 118.596429 150.301174 \n",
       "L 122.582143 149.710206 \n",
       "L 126.567857 150.167104 \n",
       "L 130.553571 149.817806 \n",
       "L 134.539286 150.882187 \n",
       "L 138.525 150.733628 \n",
       "L 142.510714 150.083934 \n",
       "L 146.496429 151.052326 \n",
       "L 150.482143 150.47607 \n",
       "L 154.467857 151.319418 \n",
       "L 158.453571 150.724406 \n",
       "L 162.439286 150.792704 \n",
       "L 166.425 151.240914 \n",
       "L 170.410714 150.976656 \n",
       "L 174.396429 150.911665 \n",
       "\" clip-path=\"url(#p5da03c141e)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 205.039219 \n",
       "L 26.925 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 222.225 205.039219 \n",
       "L 222.225 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 205.039219 \n",
       "L 222.225 205.039219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 10.999219 \n",
       "L 222.225 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 135.634375 48.911719 \n",
       "L 215.225 48.911719 \n",
       "Q 217.225 48.911719 217.225 46.911719 \n",
       "L 217.225 17.999219 \n",
       "Q 217.225 15.999219 215.225 15.999219 \n",
       "L 135.634375 15.999219 \n",
       "Q 133.634375 15.999219 133.634375 17.999219 \n",
       "L 133.634375 46.911719 \n",
       "Q 133.634375 48.911719 135.634375 48.911719 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_25\">\n",
       "     <path d=\"M 137.634375 24.097656 \n",
       "L 147.634375 24.097656 \n",
       "L 157.634375 24.097656 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- train_loss -->\n",
       "     <g transform=\"translate(165.634375 27.597656) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \n",
       "L 3263 -1509 \n",
       "L -63 -1509 \n",
       "L -63 -1063 \n",
       "L 3263 -1063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(80.322266 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(141.601562 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(169.384766 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-5f\" transform=\"translate(232.763672 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(282.763672 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(310.546875 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(371.728516 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(423.828125 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_26\">\n",
       "     <path d=\"M 137.634375 39.053906 \n",
       "L 147.634375 39.053906 \n",
       "L 157.634375 39.053906 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- val_loss -->\n",
       "     <g transform=\"translate(165.634375 42.553906) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(59.179688 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(120.458984 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-5f\" transform=\"translate(148.242188 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(198.242188 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(226.025391 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(287.207031 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(339.306641 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p5da03c141e\">\n",
       "   <rect x=\"26.925\" y=\"10.999219\" width=\"195.3\" height=\"194.04\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"238.965625pt\" height=\"242.595469pt\" viewBox=\"0 0 238.965625 242.595469\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-06-02T06:42:32.358282</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.0, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 242.595469 \n",
       "L 238.965625 242.595469 \n",
       "L 238.965625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 205.039219 \n",
       "L 225.403125 205.039219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 65.974554 205.039219 \n",
       "L 65.974554 10.999219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"mbfb2b29f7e\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbfb2b29f7e\" x=\"65.974554\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(59.612054 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 105.831696 205.039219 \n",
       "L 105.831696 10.999219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbfb2b29f7e\" x=\"105.831696\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(99.469196 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 145.688839 205.039219 \n",
       "L 145.688839 10.999219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbfb2b29f7e\" x=\"145.688839\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 30 -->\n",
       "      <g transform=\"translate(139.326339 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 185.545982 205.039219 \n",
       "L 185.545982 10.999219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbfb2b29f7e\" x=\"185.545982\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(179.183482 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 225.403125 205.039219 \n",
       "L 225.403125 10.999219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mbfb2b29f7e\" x=\"225.403125\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(219.040625 219.637656) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(112.525 233.315781) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" transform=\"translate(61.523438 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" transform=\"translate(125 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(186.181641 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" transform=\"translate(241.162109 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 30.103125 205.039219 \n",
       "L 225.403125 205.039219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m382dc3ebcb\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m382dc3ebcb\" x=\"30.103125\" y=\"205.039219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 208.838437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 30.103125 166.231219 \n",
       "L 225.403125 166.231219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m382dc3ebcb\" x=\"30.103125\" y=\"166.231219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 170.030437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 30.103125 127.423219 \n",
       "L 225.403125 127.423219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m382dc3ebcb\" x=\"30.103125\" y=\"127.423219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 131.222437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 30.103125 88.615219 \n",
       "L 225.403125 88.615219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m382dc3ebcb\" x=\"30.103125\" y=\"88.615219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 92.414437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 30.103125 49.807219 \n",
       "L 225.403125 49.807219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m382dc3ebcb\" x=\"30.103125\" y=\"49.807219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 53.606437) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_22\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m382dc3ebcb\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798437) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" transform=\"translate(63.623047 0)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(95.410156 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_23\">\n",
       "    <path d=\"M 30.103125 197.419108 \n",
       "L 34.088839 195.680831 \n",
       "L 38.074554 193.679795 \n",
       "L 42.060268 193.477667 \n",
       "L 46.045982 192.750019 \n",
       "L 50.031696 191.29472 \n",
       "L 54.017411 190.425582 \n",
       "L 58.003125 190.76919 \n",
       "L 61.988839 190.890468 \n",
       "L 65.974554 190.870255 \n",
       "L 69.960268 189.354322 \n",
       "L 73.945982 189.273469 \n",
       "L 77.931696 189.212833 \n",
       "L 81.917411 189.212832 \n",
       "L 85.903125 189.293682 \n",
       "L 89.888839 188.202205 \n",
       "L 93.874554 188.303267 \n",
       "L 97.860268 188.202208 \n",
       "L 101.845982 187.878807 \n",
       "L 105.831696 187.899018 \n",
       "L 109.817411 187.353278 \n",
       "L 113.803125 187.191581 \n",
       "L 117.788839 186.463929 \n",
       "L 121.774554 186.362869 \n",
       "L 125.760268 186.666058 \n",
       "L 129.745982 185.776707 \n",
       "L 133.731696 185.534153 \n",
       "L 137.717411 185.594798 \n",
       "L 141.703125 185.796917 \n",
       "L 145.688839 185.817132 \n",
       "L 149.674554 185.412884 \n",
       "L 153.660268 185.736279 \n",
       "L 157.645982 185.372458 \n",
       "L 161.631696 184.968205 \n",
       "L 165.617411 184.927782 \n",
       "L 169.603125 185.513942 \n",
       "L 173.588839 184.604378 \n",
       "L 177.574554 184.907569 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_24\">\n",
       "    <path d=\"M 30.103125 192.767343 \n",
       "L 34.088839 193.344842 \n",
       "L 38.074554 192.334217 \n",
       "L 42.060268 191.034842 \n",
       "L 46.045982 191.323591 \n",
       "L 50.031696 191.179218 \n",
       "L 54.017411 192.334218 \n",
       "L 58.003125 190.601717 \n",
       "L 61.988839 190.312969 \n",
       "L 65.974554 189.446718 \n",
       "L 69.960268 191.179218 \n",
       "L 73.945982 189.013593 \n",
       "L 77.931696 190.168594 \n",
       "L 81.917411 190.312969 \n",
       "L 85.903125 188.724842 \n",
       "L 89.888839 189.735466 \n",
       "L 93.874554 189.879844 \n",
       "L 97.860268 191.034842 \n",
       "L 101.845982 188.724842 \n",
       "L 105.831696 190.168594 \n",
       "L 109.817411 187.281094 \n",
       "L 113.803125 189.735466 \n",
       "L 117.788839 187.569842 \n",
       "L 121.774554 188.147343 \n",
       "L 125.760268 187.569842 \n",
       "L 129.745982 189.302342 \n",
       "L 133.731696 188.724842 \n",
       "L 137.717411 189.446718 \n",
       "L 141.703125 186.414843 \n",
       "L 145.688839 187.425468 \n",
       "L 149.674554 187.136716 \n",
       "L 153.660268 188.147343 \n",
       "L 157.645982 188.724842 \n",
       "L 161.631696 185.692967 \n",
       "L 165.617411 186.992342 \n",
       "L 169.603125 187.281094 \n",
       "L 173.588839 187.569844 \n",
       "L 177.574554 186.559216 \n",
       "\" clip-path=\"url(#pd34c459c19)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 205.039219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 205.039219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 205.039219 \n",
       "L 225.403125 205.039219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 134.640625 48.911719 \n",
       "L 218.403125 48.911719 \n",
       "Q 220.403125 48.911719 220.403125 46.911719 \n",
       "L 220.403125 17.999219 \n",
       "Q 220.403125 15.999219 218.403125 15.999219 \n",
       "L 134.640625 15.999219 \n",
       "Q 132.640625 15.999219 132.640625 17.999219 \n",
       "L 132.640625 46.911719 \n",
       "Q 132.640625 48.911719 134.640625 48.911719 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_25\">\n",
       "     <path d=\"M 136.640625 24.097656 \n",
       "L 146.640625 24.097656 \n",
       "L 156.640625 24.097656 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- train_acc1 -->\n",
       "     <g transform=\"translate(164.640625 27.597656) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \n",
       "L 3263 -1509 \n",
       "L -63 -1509 \n",
       "L -63 -1063 \n",
       "L 3263 -1063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(39.208984 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(80.322266 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(141.601562 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(169.384766 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-5f\" transform=\"translate(232.763672 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(282.763672 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(344.042969 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(399.023438 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(454.003906 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_26\">\n",
       "     <path d=\"M 136.640625 39.053906 \n",
       "L 146.640625 39.053906 \n",
       "L 156.640625 39.053906 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- val_acc1 -->\n",
       "     <g transform=\"translate(164.640625 42.553906) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 563 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2284 0 \n",
       "L 1503 0 \n",
       "L 191 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-76\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(59.179688 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" transform=\"translate(120.458984 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-5f\" transform=\"translate(148.242188 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(198.242188 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(259.521484 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" transform=\"translate(314.501953 0)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(369.482422 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pd34c459c19\">\n",
       "   <rect x=\"30.103125\" y=\"10.999219\" width=\"195.3\" height=\"194.04\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 初始化画图\n",
    "animator_loss = Animator(xlabel='epoch', xlim=[1, epochs], ylim=[0, 10],\n",
    "                         legend=['train_loss','val_loss'])\n",
    "animator_acc = Animator(xlabel='epoch', xlim=[1, epochs], ylim=[0, 1],\n",
    "                        legend=['train_acc1', 'val_acc1'])\n",
    "\n",
    "def format_time(seconds):\n",
    "    mins, sec = divmod(seconds, 60)\n",
    "    hrs, mins = divmod(mins, 60)\n",
    "    return f\"{int(hrs)}h {int(mins)}m {int(sec)}s\"\n",
    "\n",
    "num_epochs = epochs\n",
    "\n",
    "# 确保保存模型的目录存在\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# 记录训练开始时间（考虑之前已训练的时间）\n",
    "training_start_time = time.time() - elapsed_time_before\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Current LR: {current_lr:.2e}\")\n",
    "\n",
    "    # 训练\n",
    "    train_loss, train_acc1 = train_epoch(model, train_loader, criterion, optimizer, scaler, device, accumulation_steps)\n",
    "\n",
    "    # 验证\n",
    "    val_loss, acc_1, acc_3, acc_5 = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 绘图\n",
    "    animator_loss.add(epoch + 1, [\n",
    "        train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss,\n",
    "        val_loss.item() if isinstance(val_loss, torch.Tensor) else val_loss\n",
    "    ])\n",
    "    animator_acc.add(epoch + 1, [\n",
    "        train_acc1.item() if isinstance(train_acc1, torch.Tensor) else train_acc1,\n",
    "        acc_1.item() if isinstance(acc_1, torch.Tensor) else acc_1\n",
    "    ])\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    # 计算剩余时间（考虑之前已训练的时间）\n",
    "    elapsed_time = epoch_end_time - training_start_time\n",
    "    avg_epoch_time = elapsed_time / (epoch + 1 - start_epoch + 1e-7)  # 避免除零\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    remaining_time = avg_epoch_time * remaining_epochs\n",
    "\n",
    "    # 转换为更易读的格式\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy@1: {train_acc1:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy@1: {acc_1.item():.4f}, Val Accuracy@3: {acc_3.item():.4f}, Val Accuracy@5: {acc_5.item():.4f}\")\n",
    "    print(f\"Epoch Duration: {format_time(epoch_duration)}, Estimated Remaining Time: {format_time(remaining_time)}\")\n",
    "\n",
    "    # 更新学习率调度器\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_path = os.path.join(checkpoint_dir, 'multimodal_encoder_decoder_best.pth')\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model at epoch {epoch+1} to {best_model_path}\")\n",
    "        early_stop_counter = 0  # 重置计数器\n",
    "    else:\n",
    "        early_stop_counter += 1  # 增加计数器\n",
    "\n",
    "    # 如果验证损失连续多个 epoch 没有改善，则停止训练\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break  # 提前停止训练\n",
    "\n",
    "    # 每隔若干个 epoch 保存模型\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'multimodal_encoder_decoder_epoch_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved model at epoch {epoch+1} to {checkpoint_path}\")\n",
    "animator_loss.show()\n",
    "animator_acc.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bceea436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model for testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_70011/3863311555.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.bfloat16):\n",
      "Evaluating: 100%|██████████| 7/7 [00:16<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 2.7466;Test Accuracy@3 : 0.2463\n",
      "Test Accuracy@1 : 0.1027;Test Accuracy@5 : 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 测试评估\n",
    "\n",
    "# 加载最佳模型\n",
    "best_model_path = os.path.join(checkpoint_dir, 'multimodal_encoder_decoder_best.pth')\n",
    "if os.path.exists(best_model_path):\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    print(\"Loaded best model for testing.\")\n",
    "else:\n",
    "    print(f\"Best model not found at {best_model_path}. Skipping test evaluation.\")\n",
    "\n",
    "# 定义测试评估函数（可以与验证相同）\n",
    "\n",
    "\n",
    "test_loss ,test_acc1 ,test_acc3 ,test_acc5 = evaluate(model,test_loader,criterion,device)\n",
    "print(f\"Test Loss : {test_loss:.4f};Test Accuracy@3 : {test_acc3:.4f}\")\n",
    "print(f\"Test Accuracy@1 : {test_acc1:.4f};Test Accuracy@5 : {test_acc5:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651b3e4",
   "metadata": {},
   "source": [
    "## 评估泛化能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d60bd339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CSV files for training.\n"
     ]
    }
   ],
   "source": [
    "dataset_start_idx_zero = 9\n",
    "dataset_end_idx_zero = 10\n",
    "# 定义数据集路径\n",
    "dataset_path_zero = [f'/data2/wzj/Datasets/DeepSense/scenario{i}/' for i in range(dataset_start_idx_zero, dataset_end_idx_zero)]  # scenario1 ~ scenario8\n",
    "\n",
    "data_csv_paths_zero = []\n",
    "for path in dataset_path_zero:\n",
    "    data_csv_paths_zero.extend(glob.glob(os.path.join(path, '*.csv')))\n",
    "\n",
    "print(f\"Found {len(data_csv_paths_zero)} CSV files for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5740bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_paths': ['/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2703_16_45_08.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2704_16_45_08.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2705_16_45_08.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2706_16_45_08.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2707_16_45_08.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2708_16_45_08.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2709_16_45_09.jpg',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/camera_resized/image_BS2_2710_16_45_09.jpg'],\n",
       " 'heatmap_paths': ['/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_23.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_24.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_25.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_26.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_27.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_28.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_29.png',\n",
       "  '/data2/wzj/Datasets/DeepSense/scenario9/./unit1/mmWave_heatmap/mmWave_power_30.png'],\n",
       " 'gps': tensor([[-2.5033e-06,  1.3672e-04],\n",
       "         [-6.6133e-06,  1.3672e-04],\n",
       "         [-1.0663e-05,  1.3682e-04],\n",
       "         [-1.4653e-05,  1.3672e-04],\n",
       "         [-1.8583e-05,  1.3672e-04],\n",
       "         [-2.2453e-05,  1.3662e-04],\n",
       "         [-2.6203e-05,  1.3662e-04],\n",
       "         [-2.9803e-05,  1.3642e-04]]),\n",
       " 'mmwave': tensor([[0.0590, 0.0749, 0.0627, 0.0772, 0.0497, 0.0675, 0.0656, 0.1083, 0.0933,\n",
       "          0.0272, 0.0229, 0.0324, 0.0605, 0.0987, 0.1048, 0.0636, 0.0616, 0.1596,\n",
       "          0.1975, 0.2526, 0.2526, 0.1236, 0.0732, 0.0945, 0.1641, 0.1835, 0.2041,\n",
       "          0.3111, 0.3855, 0.4856, 0.3959, 0.2939, 0.2675, 0.2390, 0.4194, 0.7680,\n",
       "          0.9314, 1.0183, 1.0311, 0.9890, 0.9002, 0.7608, 0.5336, 0.3028, 0.0397,\n",
       "          0.0673, 0.1474, 0.2075, 0.3192, 0.4939, 0.5096, 0.6803, 0.5615, 0.4133,\n",
       "          0.2019, 0.1091, 0.0865, 0.1493, 0.0692, 0.1211, 0.1786, 0.2086, 0.3913,\n",
       "          0.0676],\n",
       "         [0.0144, 0.0446, 0.1228, 0.1919, 0.2464, 0.2595, 0.0439, 0.0557, 0.0703,\n",
       "          0.0454, 0.0782, 0.1163, 0.0655, 0.0328, 0.0381, 0.1173, 0.1030, 0.0729,\n",
       "          0.1258, 0.1964, 0.3857, 0.3563, 0.2253, 0.0765, 0.0687, 0.1159, 0.2185,\n",
       "          0.2854, 0.1292, 0.3014, 0.4189, 0.5332, 0.5329, 0.1700, 0.0961, 0.2970,\n",
       "          0.5679, 0.8538, 1.0041, 0.9921, 0.9583, 0.9512, 0.8874, 0.7011, 0.3411,\n",
       "          0.1203, 0.0439, 0.0590, 0.0707, 0.1878, 0.2824, 0.4654, 0.5825, 0.6312,\n",
       "          0.5433, 0.4911, 0.3289, 0.0837, 0.0688, 0.0579, 0.0714, 0.1412, 0.2036,\n",
       "          0.0672],\n",
       "         [0.0309, 0.0691, 0.0882, 0.1294, 0.1993, 0.2902, 0.1047, 0.0675, 0.0307,\n",
       "          0.0270, 0.0847, 0.1172, 0.0872, 0.0528, 0.0398, 0.0494, 0.0801, 0.0904,\n",
       "          0.1531, 0.1445, 0.2543, 0.2810, 0.2916, 0.2350, 0.0965, 0.0571, 0.0625,\n",
       "          0.1658, 0.1113, 0.1273, 0.1814, 0.3080, 0.4696, 0.3350, 0.2587, 0.1678,\n",
       "          0.1192, 0.2347, 0.7686, 0.8835, 0.9363, 0.9837, 0.9685, 0.9235, 0.8148,\n",
       "          0.7057, 0.4031, 0.2221, 0.0596, 0.0439, 0.1088, 0.2209, 0.4624, 0.5704,\n",
       "          0.6553, 0.7635, 0.5645, 0.3552, 0.2567, 0.1239, 0.0582, 0.0457, 0.0860,\n",
       "          0.0636],\n",
       "         [0.0317, 0.1528, 0.0945, 0.0382, 0.0422, 0.0762, 0.1132, 0.0974, 0.0515,\n",
       "          0.0340, 0.0220, 0.0220, 0.0529, 0.0681, 0.0781, 0.0354, 0.0308, 0.0708,\n",
       "          0.1268, 0.0817, 0.1490, 0.0907, 0.0849, 0.2845, 0.1995, 0.1767, 0.1200,\n",
       "          0.0273, 0.0432, 0.0829, 0.1282, 0.1786, 0.3235, 0.3338, 0.4358, 0.4307,\n",
       "          0.2798, 0.1469, 0.2319, 0.4839, 0.6355, 0.9072, 0.9747, 0.9782, 0.9484,\n",
       "          0.8814, 0.7737, 0.6397, 0.3470, 0.0713, 0.0345, 0.0714, 0.1067, 0.2850,\n",
       "          0.5047, 0.6835, 0.6162, 0.5129, 0.4412, 0.4582, 0.3026, 0.1279, 0.0564,\n",
       "          0.0679],\n",
       "         [0.0452, 0.1264, 0.1248, 0.0769, 0.0331, 0.0307, 0.0500, 0.0536, 0.0357,\n",
       "          0.0968, 0.1020, 0.0558, 0.0208, 0.0460, 0.0851, 0.1359, 0.1164, 0.0382,\n",
       "          0.0347, 0.0610, 0.1041, 0.0632, 0.0654, 0.1342, 0.1702, 0.2315, 0.2823,\n",
       "          0.0936, 0.0508, 0.0549, 0.1077, 0.1832, 0.2321, 0.2222, 0.3406, 0.4122,\n",
       "          0.4027, 0.3004, 0.1417, 0.0769, 0.2100, 0.6129, 0.8672, 0.9306, 0.9469,\n",
       "          0.9308, 0.8989, 0.8598, 0.7858, 0.3818, 0.1654, 0.1385, 0.0324, 0.0685,\n",
       "          0.2554, 0.4015, 0.3773, 0.3971, 0.4454, 0.5860, 0.4801, 0.3081, 0.1569,\n",
       "          0.0668],\n",
       "         [0.0140, 0.0470, 0.0831, 0.0903, 0.0937, 0.0980, 0.0464, 0.0181, 0.0341,\n",
       "          0.0670, 0.1145, 0.1084, 0.0887, 0.0707, 0.0455, 0.1411, 0.1443, 0.0425,\n",
       "          0.0289, 0.0466, 0.0444, 0.0564, 0.1364, 0.0837, 0.1542, 0.1999, 0.2389,\n",
       "          0.2083, 0.1484, 0.1413, 0.0746, 0.1066, 0.1657, 0.1825, 0.2127, 0.2722,\n",
       "          0.2791, 0.3865, 0.3519, 0.2294, 0.1189, 0.2274, 0.5065, 0.7947, 0.9065,\n",
       "          0.9578, 0.9710, 0.9579, 0.8742, 0.7267, 0.6049, 0.5286, 0.1694, 0.1120,\n",
       "          0.0749, 0.0958, 0.1296, 0.1711, 0.2447, 0.4643, 0.5070, 0.4332, 0.2961,\n",
       "          0.0636],\n",
       "         [0.0394, 0.0662, 0.0367, 0.0424, 0.0796, 0.1074, 0.0632, 0.0554, 0.0601,\n",
       "          0.0282, 0.0508, 0.0949, 0.1682, 0.1664, 0.0787, 0.0702, 0.0675, 0.0345,\n",
       "          0.0804, 0.0793, 0.0222, 0.0304, 0.0962, 0.1194, 0.1997, 0.1552, 0.1459,\n",
       "          0.1549, 0.1605, 0.2767, 0.1208, 0.0324, 0.0677, 0.1174, 0.1570, 0.1804,\n",
       "          0.1840, 0.2338, 0.3570, 0.4073, 0.3312, 0.1695, 0.1878, 0.3521, 0.6247,\n",
       "          0.8487, 0.9233, 0.9309, 0.9031, 0.8398, 0.8204, 0.7210, 0.5417, 0.3118,\n",
       "          0.0465, 0.0538, 0.0749, 0.0836, 0.1444, 0.2611, 0.3313, 0.3100, 0.2475,\n",
       "          0.0669],\n",
       "         [0.0605, 0.1295, 0.0428, 0.0315, 0.0285, 0.0298, 0.0346, 0.0647, 0.0906,\n",
       "          0.0556, 0.0389, 0.0523, 0.1259, 0.1630, 0.1035, 0.0298, 0.0122, 0.0256,\n",
       "          0.0915, 0.0844, 0.0397, 0.0543, 0.0424, 0.0794, 0.1579, 0.1450, 0.0437,\n",
       "          0.0798, 0.0838, 0.2763, 0.2558, 0.0586, 0.0483, 0.0357, 0.0833, 0.1376,\n",
       "          0.1857, 0.1580, 0.2009, 0.3067, 0.4068, 0.3381, 0.1520, 0.0655, 0.1439,\n",
       "          0.4632, 0.7828, 0.8639, 0.9346, 0.9089, 0.9142, 0.8992, 0.7995, 0.7271,\n",
       "          0.4026, 0.1900, 0.0434, 0.0325, 0.0589, 0.0949, 0.1653, 0.1915, 0.1935,\n",
       "          0.0629]]),\n",
       " 'target_mmwave': tensor([[0.0140, 0.0470, 0.0831, 0.0903, 0.0937, 0.0980, 0.0464, 0.0181, 0.0341,\n",
       "          0.0670, 0.1145, 0.1084, 0.0887, 0.0707, 0.0455, 0.1411, 0.1443, 0.0425,\n",
       "          0.0289, 0.0466, 0.0444, 0.0564, 0.1364, 0.0837, 0.1542, 0.1999, 0.2389,\n",
       "          0.2083, 0.1484, 0.1413, 0.0746, 0.1066, 0.1657, 0.1825, 0.2127, 0.2722,\n",
       "          0.2791, 0.3865, 0.3519, 0.2294, 0.1189, 0.2274, 0.5065, 0.7947, 0.9065,\n",
       "          0.9578, 0.9710, 0.9579, 0.8742, 0.7267, 0.6049, 0.5286, 0.1694, 0.1120,\n",
       "          0.0749, 0.0958, 0.1296, 0.1711, 0.2447, 0.4643, 0.5070, 0.4332, 0.2961,\n",
       "          0.0636],\n",
       "         [0.0394, 0.0662, 0.0367, 0.0424, 0.0796, 0.1074, 0.0632, 0.0554, 0.0601,\n",
       "          0.0282, 0.0508, 0.0949, 0.1682, 0.1664, 0.0787, 0.0702, 0.0675, 0.0345,\n",
       "          0.0804, 0.0793, 0.0222, 0.0304, 0.0962, 0.1194, 0.1997, 0.1552, 0.1459,\n",
       "          0.1549, 0.1605, 0.2767, 0.1208, 0.0324, 0.0677, 0.1174, 0.1570, 0.1804,\n",
       "          0.1840, 0.2338, 0.3570, 0.4073, 0.3312, 0.1695, 0.1878, 0.3521, 0.6247,\n",
       "          0.8487, 0.9233, 0.9309, 0.9031, 0.8398, 0.8204, 0.7210, 0.5417, 0.3118,\n",
       "          0.0465, 0.0538, 0.0749, 0.0836, 0.1444, 0.2611, 0.3313, 0.3100, 0.2475,\n",
       "          0.0669],\n",
       "         [0.0605, 0.1295, 0.0428, 0.0315, 0.0285, 0.0298, 0.0346, 0.0647, 0.0906,\n",
       "          0.0556, 0.0389, 0.0523, 0.1259, 0.1630, 0.1035, 0.0298, 0.0122, 0.0256,\n",
       "          0.0915, 0.0844, 0.0397, 0.0543, 0.0424, 0.0794, 0.1579, 0.1450, 0.0437,\n",
       "          0.0798, 0.0838, 0.2763, 0.2558, 0.0586, 0.0483, 0.0357, 0.0833, 0.1376,\n",
       "          0.1857, 0.1580, 0.2009, 0.3067, 0.4068, 0.3381, 0.1520, 0.0655, 0.1439,\n",
       "          0.4632, 0.7828, 0.8639, 0.9346, 0.9089, 0.9142, 0.8992, 0.7995, 0.7271,\n",
       "          0.4026, 0.1900, 0.0434, 0.0325, 0.0589, 0.0949, 0.1653, 0.1915, 0.1935,\n",
       "          0.0629]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_dataset = QwenVisionDataset(\n",
    "    data_csv_paths_zero,\n",
    "    input_length=8,\n",
    "    output_length=3\n",
    ")\n",
    "zeroshot_dataset[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "239a9d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching dataset: 100%|██████████| 5012/5012 [05:34<00:00, 14.96it/s]\n"
     ]
    }
   ],
   "source": [
    "cached_zeroshot = CachedVisionDataset(zeroshot_dataset, processor)\n",
    "zeroshot_dataloader = DataLoader(\n",
    "    cached_zeroshot,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(collate_fn, device=\"cpu\"),  # 绑定设备参数\n",
    "    pin_memory=True if device.type == \"cuda\" else False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f269ac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/7 [00:00<?, ?it/s]/tmp/ipykernel_70011/3863311555.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.bfloat16):\n",
      "Evaluating: 100%|██████████| 7/7 [00:16<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroshot loss: 2.7685\n",
      "Zeroshot acc@1: 0.0841\n",
      "Zeroshot acc@3: 0.2478\n",
      "Zeroshot acc@5: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zeroshot_loss ,zeroshot_acc_1 ,zeroshot_acc_3 ,zeroshot_acc_5 = evaluate(model,val_loader,criterion,device)\n",
    "print(f\"Zeroshot loss: {zeroshot_loss:.4f}\")\n",
    "print(f\"Zeroshot acc@1: {zeroshot_acc_1:.4f}\")\n",
    "print(f\"Zeroshot acc@3: {zeroshot_acc_3:.4f}\")\n",
    "print(f\"Zeroshot acc@5: {zeroshot_acc_5:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
